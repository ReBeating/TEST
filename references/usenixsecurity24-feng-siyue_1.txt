         FIRE: Combining Multi-Stage Filtering with Taint Analysis
               for Scalable Recurring Vulnerability Detection
  Siyue Feng, National Engineering Research Center for Big Data Technology and System, Services Computing
 Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research
     Center on Big Data Security, Cluster and Grid Computing Lab; School of Cyber Science and Engineering,
 Huazhong University of Science and Technology; Yueming Wu, Nanyang Technological University; Wenjie Xue
 and Sikui Pan, National Engineering Research Center for Big Data Technology and System, Services Computing
 Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research
     Center on Big Data Security, Cluster and Grid Computing Lab; School of Cyber Science and Engineering,
Huazhong University of Science and Technology; Deqing Zou, National Engineering Research Center for Big Data
 Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed
   System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab;
 School of Cyber Science and Engineering, Huazhong University of Science and Technology; Jinyinhu Laboratory;
    Yang Liu, Nanyang Technological University; Hai Jin, National Engineering Research Center for Big Data
 Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed
   System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab;
          School of Computer Science and Technology, Huazhong University of Science and Technology
                 https://www.usenix.org/conference/usenixsecurity24/presentation/feng-siyue


                 This paper is included in the Proceedings of the
                        33rd USENIX Security Symposium.
                         August 14–16, 2024 • Philadelphia, PA, USA
                                            978-1-939133-44-1

                                                          Open access to the Proceedings of the
                                                            33rd USENIX Security Symposium
                                                                is sponsored by USENIX.
FIRE: Combining Multi-Stage Filtering with Taint Analysis for Scalable Recurring
                          Vulnerability Detection
      Siyue Feng1,2 , Yueming Wu4∗, Wenjie Xue1,2 , Sikui Pan1,2 , Deqing Zou1,2,5 , Yang Liu4 , Hai Jin1,3
     1 National Engineering Research Center for Big Data Technology and System, Services Computing

    Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering
                    Research Center on Big Data Security, Cluster and Grid Computing Lab
      2 School of Cyber Science and Engineering, Huazhong University of Science and Technology, China
    3 School of Computer Science and Technology, Huazhong University of Science and Technology, China
                                4 Nanyang Technological University, Singapore
                                        5 Jinyinhu Laboratory, China

                        Abstract                         based on deep learning [14, 15, 26, 40, 57].
With the continuous development of software open-sourcing,             However, traditional vulnerability detection methods typi-
the reuse of open-source software has led to a significant in-      cally require manually defined rules and heavily rely on exper-
crease in the occurrence of recurring vulnerabilities. These        tise in vulnerability-related domains. Intelligent vulnerability
vulnerabilities often arise through the practice of copying and     detection methods based on deep learning demand substantial
pasting existing vulnerabilities. Many methods have been pro-       labeled datasets for training, depending on both the quantity
posed for detecting recurring vulnerabilities, but they often       and exactness of the labeled datasets. Therefore, it is difficult
struggle to ensure both high efficiency and consideration of        for them to achieve large-scale vulnerability detection. In fact,
semantic information about vulnerabilities and patches. In          with the continuous development of software open-sourcing,
this paper, we introduce FIRE, a scalable method for large-         reusing open-source software has become a common practice
scale recurring vulnerability detection. It utilizes multi-stage    in software development. This trend results in an increasing
filtering and differential taint paths to achieve precise clone     number of recurring vulnerabilities. These vulnerabilities ex-
vulnerability scanning at an extensive scale. In our evaluation     hibit similar characteristics, share code logic, or may even
across ten open-source software projects, FIRE demonstrates         be identical, hence they are also known as clone vulnerabili-
a precision of 90.0% in detecting 298 recurring vulnerabilities     ties. Conventional vulnerability detection techniques can only
out of 385 ground truth instance. This surpasses the perfor-        leverage the general behaviors of the majority of vulnerabili-
mance of existing advanced recurring vulnerability detection        ties, lacking precise identification for recurring vulnerabilities
tools, detecting 31.4% more vulnerabilities than VUDDY and          that reuse specific behavior vulnerabilities. Moreover, they
47.0% more than MOVERY. When detecting vulnerabilities              are not suitable for detecting vulnerabilities in large-scale
in large-scale software, FIRE outperforms MOVERY by sav-            open-source software. Therefore, when certain vulnerabili-
ing about twice the time, enabling the scanning of recurring        ties are known, it is necessary to design novel techniques to
vulnerabilities on an ultra-large scale.                            rapidly identify widely prevalent recurring vulnerabilities in
                                                                    real-world code environments on a large scale.
1     Introduction
                                                                       Existing Approaches. Existing methods [8, 27, 29, 52, 53,
Vulnerabilities refer to security issues such as errors, defects,
                                                                    54, 56] specifically designed for detecting recurring vulnera-
bugs, and other flaws in software. They arise due to logi-
                                                                    bilities extract lexical, syntactic, or semantic signatures rich in
cal errors, non-compliance with coding standards, low code
                                                                    vulnerability information from known vulnerabilities. Clones
quality in the code-writing process, or the lack of security
                                                                    matching these signatures are considered potential vulnera-
testing. Vulnerabilities expose software to threats such as
                                                                    bilities. These methods rely on the exactness of the extracted
information leakage, remote control, and denial of service
                                                                    vulnerability features. If the extracted features are too simple
attacks. Exploiting vulnerabilities, hackers can compromise
                                                                    or cannot precisely capture the vulnerability behavior, it may
the security of software systems and networks, leading to
                                                                    lead to false positives or false negatives. In addition to consid-
severe consequences. Therefore, timely vulnerability detec-
                                                                    ering vulnerability features, adding consideration for patch
tion is crucial for enhancing software security. Various meth-
                                                                    information is essential to distinguish whether the function
ods for vulnerability detection exist today, including tradi-
                                                                    is a patched vulnerability (false positive) or a genuine vul-
tional approaches such as manual inspection, static analysis
                                                                    nerability. Moreover, as the size of open-source communities
[17, 35, 45, 46], fuzz testing [7, 12, 32, 42, 51], symbolic ex-
                                                                    continues to grow, it requires a substantial time investment to
ecution [5, 10, 22, 44]. Additionally, there are some methods
                                                                    handle the massive amount of code for detection. The time
    ∗ Yueming Wu is the corresponding author.                       gap between the appearance and discovery of vulnerabilities



USENIX Association                                                                     33rd USENIX Security Symposium            1867
may lead to further propagation of vulnerabilities. Therefore,      and vulnerabilities, achieving filtering at the lexical level. Fi-
there is a current need for a method that can: 1) Enable rapid      nally, we incorporate patch functions, conduct static analysis
detection of extremely large-scale recurring vulnerabilities. 2)    on functions to extract abstract syntax trees (ASTs), and use
Support for detecting vulnerabilities that make syntactically       improved AST similarity to calculate the similarity among
different but semantically identical changes. 3) Consider the       target functions, vulnerable functions, and patch functions,
differences between vulnerabilities and patches.                    achieving filtering at the syntactic level.
   Among existing recurring vulnerability detection tools,             Evaluation. We implement a prototype system, FIRE, and
VUDDY [29] supports large-scale vulnerability scanning              conduct testing on ten open-source software projects, com-
through a length filtering technique that reduces the number        paring its performance with two state-of-the-art recurring vul-
of signature comparisons. However, it can not detect clone          nerability detectors (i.e., VUDDY [29] and MOVERY [53]).
vulnerabilities with syntactic changes and does not consider        Specifically, FIRE identifies 298 instances of recurring vul-
patch information. To address this, MOVERY [53] detects             nerabilities, which is 2.55 times the number discovered by
syntactic clone vulnerabilities by adding the oldest version of     MOVERY. Moreover, it achieves higher precision, with a
vulnerability and patch functions. However, the introduction        23.2% improvement compared to VUDDY, and a 40.4% im-
of control flow and data flow information and matching at           provement compared to MOVERY. The recall also increases
line granularity leads to low efficiency of MOVERY. Even if         by 31.4% and 47%, respectively. While maintaining good
MOVERY reduces the search scope by obtaining public func-           precision and recall, FIRE demonstrates high efficiency. Par-
tions with identical syntax through path information, it only       ticularly in the case of large-scale projects, it can save half the
reduces the number of candidate functions by half, and the          time compared to MOVERY. Furthermore, we also compare
time overhead remains high. Furthermore, while MOVERY               FIRE with two advancing learning-based methods (i.e., RE-
considers the differences between vulnerabilities and patches       VEAL [11] and VulBERTa [23]), two static analysis-based
in most cases, it does not consider the statement order when        vulnerability detectors (i.e., Checkmarx [1] and FlawFinder
extracting vulnerability and patch features. This lack of con-      [2]), and two general code clone detection tools (i.e., Sourcer-
sideration may result in false positives by not thoroughly          erCC [43] and Lazar et al. [30]). The experimental results
analyzing the behavioral differences between vulnerabilities        indicate that FIRE outperforms these approaches as well.
and patches.                                                           Contribution. In summary, our method makes the follow-
   Our Approach. To address the limitations of existing tools,      ing contributions:
we propose utilizing taint analysis to maximize the behav-             • We propose a scalable recurring vulnerability detection
ioral differences between vulnerabilities and patches. Taint              method based on multi-stage filtering that extracts se-
analysis techniques have been widely employed in vulnera-                 mantic signatures of vulnerabilities and patches through
bility detection, providing a precise characterization of the             differential tainted paths.
semantic behavior of software [21, 28, 37]. Specifically, we           • We implement a prototype system called FIRE 1 for ef-
perform taint analysis on vulnerable functions, concurrently              fective and scalable detection of recurring vulnerabilities
conducting data-flow analysis for taint propagation. This al-             in open-source software.
lows us to extract the propagation paths of tainted markers in         • We conduct an in-depth comparative evaluation of FIRE
the program, resulting in tainted paths. Furthermore, we not              against state-of-the-art vulnerability detection methods.
only extract tainted paths of vulnerabilities but also perform            The results demonstrate that FIRE can achieve large-
the same tainted path extraction operation for patches. Subse-            scale vulnerability scanning with superior precision and
quently, we focus solely on the differential aspects between              recall.
vulnerabilities and patches. We consider the differential paths
as signatures of vulnerabilities and patches.                       2     Related Work
   However, the use of taint analysis comes with a high cost.       This section introduces related works closely associated with
To make taint analysis feasible for ultra-large-scale vulnera-      recurring vulnerability detection, including code clone detec-
bility scanning, we propose a multi-stage filtering approach.       tion methods and recurring vulnerability detection methods.
This approach filters vulnerabilities at three levels: simple          Code Clone Detection Techniques. Many techniques have
vulnerability features, lexical features, and syntactic features,   been proposed to detect code clones (e.g., [18, 24, 25, 50, 55,
enabling taint analysis to be applicable to ultra-large-scale       59]). Some are designed for high precision in detecting com-
vulnerability scanning. Firstly, we extract vector representa-      plex clones, while others focus on achieving high efficiency.
tions for each function based on their simple features. Then,       However, these methods primarily aim at detecting general
we employ our innovative Shuffle Fuzzy Bloom Filter, which          code clones rather than recurring vulnerabilities. There are
supports approximate membership queries, to filter at the level     two reasons why code clone detectors cannot be used directly
of simple vulnerability features. Secondly, we extract token        for vulnerable code clone detection: Firstly, the code differ-
sequences from functions and then utilize traditional token
similarity to compute the similarity between target functions           1 https://github.com/CGCL-codes/FIRE.




1868    33rd USENIX Security Symposium                                                                          USENIX Association
ences between vulnerable functions and their patched versions        ing between vulnerabilities and patches through tainted paths
are often small. Consequently, code clone detectors that fo-         enriched with semantic information.
cus solely on vulnerable functions may mistakenly identify
patched functions as vulnerable, leading to a high rate of                 FIRE: Combining Multi-Stage Filtering with Taint Analysis for Scalable Recurring
                                                                                                     Vulnerability Detection
false positives. Secondly, vulnerabilities are often subtle and
                                                                                                     Filtering Phase                   Vulnerability Identification
context-dependent. Code clone detectors typically analyze                    Target               Shuffle Fuzzy Bloom                            Phase
                                                                             System




                                                                                                                                Vulnerability, Patch)
the entire vulnerable function, which can result in missing                                             Filtering                                       Taint Analysis




                                                                                                                                 (Target Function,
                                                                                                    Target Function
the vulnerability if there are significant changes in areas unre-          Vulnerability
                                                                            Functions           Token Similarity Filtering                               Similarity
lated to the vulnerability. This may lead to a high rate of false                                                                                        Calculation
                                                                                             (Target Function, Vulnerability)
negatives.                                                                    Patch                                                                        Output
                                                                            Functions           AST Similarity Filtering
   Recurring Vulnerability Detection Techniques. Several
techniques have been proposed for detecting recurring vulner-
abilities [8, 27, 29, 52, 53, 54, 56]. Jang et al. introduce ReDe-                    Figure 1: The overview of our method
Bug [27], a fast recurring vulnerability discovery technique            In this part, we focus on introducing the filtering phase
using a slicing window approach. However, the use of exact           of FIRE. Figure 1 gives the overview of our filtering phase,
matching leads to numerous false negatives, and matching             which consists of three stages: Bloom Filter, Token Filter,
only the context information of vulnerability-modified lines         and AST Filter. The precision of the three-stage filtering
introduces many false positives. Kim et al. present VUDDY            increases incrementally, accompanied by a gradual increase
[29], a scalable vulnerable code clone discovery technique for       in time overhead. However, each filtering stage in our method
large-scale software. However, VUDDY relies on normaliza-            significantly reduces the number of functions to be inspected
tion and abstraction, and can only detect fully identical and        in the subsequent stage. This substantially improves the over-
renamed clone vulnerabilities, missing variations with slight        all speed of our method. In the filtering phase, the source
modifications. Additionally, due to the lack of patch infor-         code of the target software is input, and the output is poten-
mation, VUDDY might misidentify already patched secure               tially vulnerable target functions with vulnerability and patch
functions as vulnerabilities. Bowman et al. propose VGRAPH           function pairs similar to them.
[8], a graph-based recurring vulnerability discovery technique
that is more robust to code modifications, especially for vul-       3.1       Bloom Filter
nerabilities with syntax changes. Xiao et al. introduce MVP          Bloom Filter is a concise data structure that uses a bit array to
[56], which discovers recurring vulnerabilities with syntactic       represent a set and efficiently determines whether an element
similarity by considering code lines directly related to vulner-     belongs to that set. It is known for its high space and time effi-
abilities. Woo et al. present MOVERY [53], which identifies          ciency and finds applications in various network-related tasks
recurring vulnerabilities induced by internal OSS modifica-          such as traffic identification [19], optimal replacement [39],
tions by adding information from the oldest version of vul-          longest prefix matching [16], route lookup [9], and packet
nerabilities. However, these methods have limited efficiency         classification [6]. If we abstract the recurring vulnerability
(i.e., they require more time overhead to detect vulnerabili-        detection as a set inclusion problem, determining whether a
ties), making it challenging to support large-scale recurring        function is vulnerable is equivalent to checking if it belongs
vulnerability detection.                                             to the set of vulnerabilities. Despite the potential for false pos-
   In this paper, we propose an accurate and scalable recurring      itives in Bloom Filter, our method leverages them as a filter
vulnerability detection method, which is designed for large-         to discard functions that clearly do not meet the conditions.
scale security assessments of open-source software. This ap-         For functions that may incur false positives, subsequent filter-
proach employs multi-stage filtering to address the efficiency       ing stages are implemented to address them. Given the rapid
issues present in current methods. Additionally, it enhances         speed of Bloom Filter, they are particularly suitable as the first
detection effectiveness by utilizing differential taint paths to     filtering stage in our method to eliminate highly dissimilar
extract semantic signatures for vulnerabilities and patches,         functions. Therefore, we consider using Bloom Filter for the
thereby addressing the issues of current methods that do not         first stage of our filtering process.
consider the differences between vulnerabilities and patches,        3.1.1 Preprocessing
and neglect semantic information.                                    Before filtering with Bloom Filter, we preprocess all functions
                                                                     in the target software. Developers often add comments and
3   Filtering Phase                                                  empty lines to aid in code writing and understanding. These
As shown in Figure 1, our proposed method (i.e., FIRE) com-          comments may introduce unnecessary noise for recurring vul-
prises two phases: filtering phase and vulnerability identifi-       nerability detection. To address this, we begin by removing
cation phase. The filtering phase improves efficiency by re-         comments and blank lines from each function before perform-
ducing the number of candidate functions. The vulnerability          ing any operations. This normalization process ensures that
identification phase improves the effectiveness by distinguish-      our method can adapt to changes in code formatting or com-



USENIX Association                                                                              33rd USENIX Security Symposium                                         1869
ments. In addition, similar to the previous approach [29, 53],                                calculated from the length of the bit array M and the number
we discard the functions with less than five lines of code                                    of elements N added to the Bloom Filter (Equation 2).
(LOC) after normalization. Because the probability of these                                      We apply the standard Bloom Filter for recurring vulner-
simple functions having vulnerabilities is low. This operation                                ability detection. First, we extract feature vectors for each
substantially reduces the number of functions to be inspected,                                vulnerability in the vulnerability dataset to form a set of vul-
thereby enhancing the efficiency of our method.                                               nerability vectors. Then, each element (feature vector) in the
3.1.2 Standard Bloom Filter                                                                   set has been inserted into the Bloom Filter, including the
Bloom Filter consists of H hash functions and an M-bit array                                  vulnerability vector A2 (1,2,3,4,5) in Figure 2. Two hash func-
used to represent the set S. Each element in the array can be                                 tions are applied to A2 to get hash values 4 and 9, so the 4th
either zero or one. The number of hash functions (i.e., H)                                    and 9th position in the Bloom Filter’s bit array are set to 1,
is between 1 and M − 1. As shown in Figure 2, the steps                                       as shown in Figure 2. When a vector B2 (1,2,3,4,6) of target
for inserting and querying elements in Bloom Filter are as                                    function is queried, since the last element of this vector is
follows:                                                                                      different from A2 , hashing B2 will yield 7 and 10. Neither of
                                                                                              these positions in the bit array is 1. Therefore, it is determined
       Initialization   0    0    0      0      0     0       0       0    0        0         that the target function is not vulnerable. In fact, A2 is very
                                  A1                         A2                               similar to B2 , differing in only one feature. As a result, stan-
         Insertion           h1(A1)                               h2(A2)
                                       h2(A1)       h1(A2)                                    dard Bloom Filter only supports exact membership queries, so
                        0    1    0      1      0     1       0       0    1        0         functions with slight modifications cannot be queried. To en-
                             h1(B1)    h2(B1)                h1(B2)        h2(B2)             hance the variety of vulnerabilities we can detect, we design
          Query
                                  B1                               B2                         a new Bloom Filter to support approximate queries, enabling
 Figure 2: Inserting and querying elements in Bloom Filter                                    the detection of similar vulnerabilities.
   Initialization: The Bloom Filter is initialized as an M-bit                                3.1.3 Shuffle Fuzzy Bloom Filter
array with all zeros.                                                                         In this part, we introduce the design of our shuffle fuzzy bloom
   Insertion: For element “A1” in the set S, H hash functions                                 filter (SFBF). It is comprised of a certain number of standard
are applied to obtain H hash values, and the positions in the                                 Bloom Filters, including the initialization parts, insertion part,
bit array corresponding to these H hash values are set to one.                                and query part.
   Query: For querying an element “B1”, H hash functions                                          The initialization part involves initializing a series of
are applied to obtain H hash values, and the positions in the                                 Bloom Filters (B1 , B2 , ..., BmaxTries ) and a series of seeds
bit array corresponding to these H hash values are checked                                    (s1 , s2 , ..., smaxTries ). We use these seeds to construct these
to see if they are all set to one. If yes, it indicates that the                              Bloom Filters during the insertion part.
queried element “B1” belongs to the set S within the range of                                     The insertion part is where we construct the Bloom Filters
false positive probability (i.e., P); otherwise, the element “B1”                             containing the vulnerability dataset. For each feature vector
does not exist in set S.                                                                      v0 of a vulnerable function, maxTries rounds of operations
   The formulas for calculating M, H, and P are as follows,                                   are needed to complete the insertion part. As illustrated in
where N represents the number of elements in the set repre-                                   Figure 3, each round of the insertion stage consists of three
sented by the Bloom Filter:                                                                   steps. We use the operation in the jth round as an example.
                                      N × ln (P)                                                 • Step 1: Shuffle v j−1 using seed s j to generate v j .
                            M=−                                                         (1)
                                        (ln2)2                                                   • Step 2: Discard the first d% positions of v j , reducing
                                 M × ln (2)                                                        the vector length to 1 − d% times of its original length,
                            H =−                                                        (2)        resulting in v j .
                                    N
                               
                                   − HN
                                         H                                                      • Step 3: Insert v j into B j .
                            P = 1−e M                                                   (3)
                                                                                                 After performing maxTries rounds of insertion operations
   Bloom Filter uses hash functions and bit arrays to represent                               for each function vector, we construct maxTries Bloom Fil-
data sets, and there may be hash conflicts leading to false pos-                              ters, forming our SFBF.
itives. Increasing the length of the byte array and the number
                                                                                                 The query part is similar to the insertion part as shown
of hash functions reduces the false positive rate but increases
                                                                                              in Figure 3, but different in Step 3. For each function fea-
the memory consumption (Equation 3). With a fixed accept-
                                                                                              ture vector t0 , multiple rounds of operations are performed to
able false positive rate P, the appropriate M can be chosen by
                                                                                              complete the query part.
the number of elements N (Equation 1). The number of hash
functions also needs to be weighed, the more hash functions                                      • Step 1: Shuffle t j−1 using seed s j to generate t j .
then the Bloom Filter will be less efficient. However, if it is                                  • Step 2: Discard the first d% positions of t j , reducing
too few then the false positive rate will become higher. There-                                    the vector length to 1 − d% times of its original length,
fore, the appropriate number of hash functions can also be                                         resulting in t j .



1870    33rd USENIX Security Symposium                                                                                                   USENIX Association
            Insertion                                                                        complete                     Step 3                            Query
                                                                                              query
                                                                                                   Yes
                                                                             If j =                         Check whether
             Step 1               Step 2           Step 3                   maxTries                                                   Step 2          Step 1
                                                                                                           vector is in the Bj
                                                            The jth Bloom                  Shuffle Fuzzy
                                                              filter Bj                    Bloom Filter

                                                                                                    No
  vectors         vectors after        vectors after                                                                    vector after        vector after        vector
                    shuffle              discard                                                                          discard             shuffle

             next round of Bloom filter Bj+1 insertion                                                         next round of Bloom filter Bj+1 query

                          Figure 3: Each round of the insertion part and query part in Shuffle Fuzzy Bloom Filter

   • Step 3: Check whether t j is in the B j . If it is, the query                     we add eight less common operators. GraphSPD does not
     vector completes the query stage in the jth round of                              contain format strings, but buffer overflows, format string
     operations; otherwise, new rounds of query operations                             vulnerabilities, and other types of vulnerabilities are closely
     continue until the query stage is completed or the maxi-                          related to format strings. Therefore, we add 20 format strings.
     mum number of operations, maxTries, is reached.                                   Overall, given the syntactic features of vulnerabilities, we
                                                                                       extract 177 features belonging to four groups from each code
   We use the SFBF to query B2 in Section 3.1.2. Since it has
                                                                                       snippet. The specific feature and descriptions are shown in
the operation of shuffle and discard, then the nth round of the
                                                                                       Table 4 in Appendix A.
insertion phase will shuffle A2 (1,2,3,4,5) to (5,4,3,1,2) and
discard the first element to get A′2 (4,3,1,2). B2 (1,2,3,4,6) in                         These different crucial features correspond to different vul-
the query phase of the nth round is also shuffled to (6,4,3,1,2),                      nerability types. The sensitive APIs, formatting strings, oper-
which yields B′2 (4,3,1,2) after discarding the first element.                         ators, or keywords used by different vulnerability types differ.
Since A2 and B2 discard the only different element, A′2 and                            For example, buffer overflow vulnerabilities are more related
B′2 are exactly the same. Therefore, the SFBF can query B2 ,                           to formatted strings and memory allocation functions (e.g.,
which is implemented to support the querying of slightly                               “malloc”, “alloc”). Unauthenticated user input vulnerabilities
modified functions.                                                                    are more relevant to formatted string functions (e.g., “printf ”,
                                                                                       “sprintf ”). Out-of-bounds write and out-of-bounds read vulner-
3.1.4 Crucial Features of Vulnerabilities                                              abilities are related to sensitive APIs of “copy” and “sizeof ”,
Second, in order to achieve the filtering of similar vulnerabili-                      and pointer-related operations. The null pointer dereference
ties, we extract crucial features to construct feature vectors,                        vulnerability is related to the use of the dereference operator
and hash the vectors instead of hashing the entire code in-                            * and NULL pointers.
formation of a function. We introduce the crucial features                                We focus exclusively on these 177 crucial features and
of vulnerabilities that we select and construct feature vec-                           based on the presence of these features in each function,
tors based on these features. Recent research [33] and [49]                            we generate the feature vector. First, we initialize a 177-
emphasize the significant correlation between source code                              dimensional feature vector with all zeros for each function.
vulnerabilities and specific syntactic features. For instance,                         Then, if a feature exists, the value at the corresponding posi-
syntax structures involving pointers and arrays in the source                          tion in the vector is set to one. This process creates the feature
code are often vulnerable, as these operations frequently lead                         vectors for each function, preparing for the efficient filter-
to out-of-bounds access or NULL pointer dereference. Addi-                             ing of potential vulnerable functions in SFBF. Utilizing our
tionally, specific arithmetic expressions may indicate potential                       SFBF for the initial stage of filtering helps reduce irrelevant
improper operations, such as integer overflow.                                         functions in the target software by 80.63% (refer to Section
   Recent research GraphSPD [47] extracts features that re-                            5.5). This substantial reduction of functions to be analyzed in
flect syntactic information about vulnerabilities. Therefore,                          subsequent steps significantly improves the overall speed.
we borrow the key features extracted in GraphSPD and make
modifications and extensions based on them. Specifically,                              3.2    Token Similarity Filter
GraphSPD only considers identifiers and literal features (e.g.,                        The SFBF only filters out functions that do not contain simi-
variables, numbers, strings, pointers, arrays, null identifiers),                      lar features to vulnerable functions. However, there are cases
and some keywords related to control flow. In order to capture                         where functions have the same vulnerability features but dif-
more functional features and consider more types of vulnera-                           fer lexically from the vulnerable functions. The SFBF lacks
bilities, we extend them to include all 73 C/C++ keywords,                             the ability to discard such functions. Therefore, as the second
thus covering a wider range of features and structures in the                          filtering stage, we consider extracting the tokens of functions
code. GraphSPD contains only 34 regular operators, to which                            to increase consideration of lexical information. In this stage,



USENIX Association                                                                                            33rd USENIX Security Symposium                       1871
we parse the functions and extract their token sets. For exam-         vulnerable function and Fp to represent the patched function
ple, the token set of the code “int a = b*c” consists of “int”,        after fixing the vulnerability. Deleted lines refer to the lines
“a”, “=”, “b”, “*”, and “c”. Then we calculate the similarity          that appear in Fv but not in Fp , while added lines refer to the
score between the token sets of the function to be examined            lines that do not appear in Fv but are present in Fp . Therefore,
and the vulnerable functions, and retain the functions with            for a given pair of functions (Fv , Fp ), we further define Sdel as
similarity scores above a threshold (i.e., T1 ) along with all cor-    all deleted statements and Sadd as all added statements. The
responding similar vulnerabilities. We use a simple similarity         target functions eligible for syntactic similarity analysis must
calculation method (i.e., Jaccard similarity) to compute the           meet the following two conditions:
similarity between token sets, ensuring high efficiency.                   • C1: The target function (F) must incorporate all deleted
   Jaccard similarity is commonly used to compare the sim-                   statements, i.e., ∀h ∈ Sdel , h ∈ F.
ilarity between sets. Given two sets A and B, the Jaccard                  • C2: The target function must not include any of the
similarity is defined as the ratio of the size of the intersection           added statements, i.e., ∀h ∈ Sadd , h ∈ / F.
of A and B to the size of the union set, it is calculated as:             C1 is to ensure that there are deleted statements in the tar-
                             |A ∩ B|       |A ∩ B|                     get function that are directly related to how the vulnerability
          Jaccard (A, B) =           =                          (4)    is created. C2 is to ensure that there are no added statements
                             |A ∪ B| |A| + |B| − |A ∩ B|
                                                                       in the target function that are directly related to how the vul-
    Notably, variable names are not symbolized because in the          nerability is fixed.
subsequent taint analysis phase, we need to extract the data           3.3.2 Syntactic Similarity Analysis
flow based on the variable names to complete the paths collec-
                                                                       We then employ AST generated from source code for simi-
tion. Generally, incorrectly excluding functions with different
                                                                       larity comparison. Specifically, we measure the similarity by
variable names but identical content does not occur frequently.
                                                                       calculating the number of nodes shared between two ASTs
This is because tokenization divides the entire function into
                                                                       (i.e., Jaccard similarity).
small granularities, with variable names constituting only a
very small part of the token set. If a function differs from a                                 int a = b*c
vulnerability function solely in the variable names but has the
same content, the Jaccard similarity scores between the two                              int    a=b*c

would not be sufficiently low to result in incorrect exclusion.                           a        =         b*c
    After the filtering based on token similarity, not only are
                                                                                                    b         *      c
functions dissimilar lexically from the vulnerable functions
filtered out, but each suspicious function is also provided                    Figure 4: The AST of the code “int a = b*c”
with a list of potential reused vulnerabilities. Consequently, in         We employ AST as the objects of comparison because
the subsequent filtering and detection steps, there is no need         compared to other graph representations, extracting AST of
to compare the suspicious function with all vulnerabilities.           function does not require compilation and is very fast. For
Instead, it only needs further validation against the potentially      example, Figure 4 illustrates the AST of the code “int a =
reused vulnerabilities. In summary, this filtering stage further       b*c”. The node “b*c” has three child nodes: “b”, “*”, and “c”.
improves the speed of our method by reducing the number of             Nodes shaded in light blue in Figure 4 represent the leaf nodes
functions to be examined and narrowing down the matching               (i.e., nodes without child nodes). The leaf node sequence of
candidates for each suspicious function. By using the second           each AST corresponds to the token sequence of the code line.
step of token similarity filtering, we are able to filter out          The AST not only encompasses the token sequence of the
99.82% (refer to Section 5.5) of the irrelevant functions.             code but also encodes syntactic information, representing the
                                                                       hierarchical structure of code decomposition. In this stage, we
3.3    AST Similarity Filter
                                                                       experiment with various algorithms to calculate the similarity
In the previous filtering, we only consider the lexical similar-       between two ASTs, including 1) traditional hash-based com-
ity between target functions and vulnerabilities. However, a           parison methods [60], 2) computing the similarity between
patched secure function may have a very high lexical similar-          sequences by deep traversal of AST nodes, 3) computing the
ity with the vulnerability. Therefore, in the final filtering stage,   similarity by calculating the number of edges shared between
we introduce patch functions to further calculate the syntactic        two ASTs, and 4) computing the similarity by directly calcu-
similarity between target functions, vulnerable functions, and         lating the number of nodes shared between two ASTs (i.e.,
patch functions. This helps filter candidate functions based           Jaccard similarity). Our experimental results show that calcu-
on syntactic similarity.                                               lating simple Jaccard similarity between nodes is sufficient for
3.3.1 Delete Lines and Add Lines                                       rapidly and accurately assessing the similarity between two
Similar to the previous work [53, 56], before performing the           ASTs. Therefore, we choose it to compute the AST similarity.
syntactic similarity analysis, we first perform line-level fil-           Moreover, we also consider the syntactic information of
tering based on two conditions. We use Fv to represent the             patch functions and simultaneously calculate the similarity



1872    33rd USENIX Security Symposium                                                                             USENIX Association
between the ASTs of the target function, vulnerable function,           Therefore, we use taint analysis to extract signatures, pay-
and patch function. If the similarity with the vulnerability is      ing more attention to the sensitive information and seman-
higher and exceeds a threshold (i.e., T2 ), we retain the target     tic details within functions, allowing us to detect recurring
function for further fine-grained semantic analysis, otherwise       vulnerabilities at a finer-grained semantic level. Specifically,
we discard the target function. In summary, the target function      we perform taint analysis on each function, extracting all
must satisfy the following conditions:                               <sources, sinks> points in the function. Unlike regular taint
    • C3: The similarity between target function and vulnera-        analysis, we do not consider sanitizers, meaning we do not
      ble function should surpass a predefined threshold, i.e.,      check whether taint (i.e., sensitive data) has been neutralized.
      Sim (AST _F, AST _Fv ) ≥ T2 .                                  The sanitization analysis requires a series of measures for ver-
                                                                     ification and confirmation, which would introduce additional
    • C4: The target function should have a higher syn-
                                                                     processing overhead. Hence, we only focus on the <sources,
      tactically similarity to the vulnerable function, i.e.,
                                                                     sinks> tuples. In response to the extracted tuple, we conduct
      Sim (AST _F, AST _Fv ) ≥ Sim (AST _F, AST _Fp ).
                                                                     taint propagation analysis by considering data dependency
   This AST-based similarity filter evaluates the syntactic sim-     relationships. We extract the propagation paths of tainted data
ilarity between the target function and both the vulnerable          in the program, which we refer to as the taint paths. These
and patched functions. It enhances precision while reducing          paths constitute the signature of the function. We use Joern
the false positives associated with patch matching.                  [58] for taint analysis. Joern generates code property graph
3.4    Summary to Filtering Phase                                    (CPG) for function. CPG is a graphical representation that
                                                                     covers information about AST, control flow graph (CFG), and
Using SFBF for the initial coarse-grained filtering signifi-
                                                                     program dependence graph (PDG). A CPG consists of nodes
cantly reduces the number of irrelevant functions in the target
                                                                     and their types, labeled directed edges, and key-value pairs.
software. This reduction substantially decreases the number
                                                                     We get parameters and variables by getting nodes with node
of functions that need to be analyzed in subsequent steps. The
                                                                     type “identifier”, which we consider as sources, and we get all
token filter not only filters out functions that are dissimilar to
                                                                     function calls by getting nodes with node type “call”, which
vulnerabilities lexically but also provides a list of potential
                                                                     we consider as sinks. Joern provides the “reachableByFlows”
vulnerabilities for each suspicious function. Consequently, in
                                                                     method to analyze the possible data flow between the speci-
the subsequent AST filter, there is no need to compare suspi-
                                                                     fied nodes. By using this method, all the paths from sources
cious functions with all vulnerable functions, but only with
                                                                     to sinks can be obtained.
potentially reusable vulnerabilities. The AST filter compares
the target function with the vulnerable and patch functions,
                                                                        1. int foo(size_t size) {
and the target functions meeting the criteria are passed to the         2.     int result = -1;            size    size<=0       malloc
                                                                        3.     void *buffer;
subsequent detection stages. This reduction in the number of            4.     if (size <= 0)
                                                                        5.     return result;             buffer   buffer         bar
functions to be analyzed further enhances the speed of FIRE.            6.     buffer = malloc(size);
                                                                        7.     result = bar(buffer,        size    size<=0       buffer       bar
4     Vulnerability Identification Phase                                8.
                                                                           size);
                                                                               return result;
                                                                        9. }             1. source code             3. taint propagation paths
The vulnerability identification phase involves signature ex-
traction and vulnerability detection. In the signature ex-                              2. <src, sink>     1       4         6    4. taint paths
                                                                       <size, malloc>
traction phase, we perform taint analysis on target functions,                                             3       6         7
vulnerable functions, and patch functions to extract taint prop-
                                                                        <buffer, bar>    <size, bar>
agation paths. In the vulnerability detection phase, the simi-                                             1       4         6            7
larity between the tainted paths of the target function and the              Figure 5: Extract taint paths from source code
divergent parts of the taint paths between the vulnerability
and patch is calculated. This is done to determine if the target         For example, consider the function in Figure 5 that con-
function represents a vulnerability.                                 tains three variables: “size”, “result”, and “buffer”. Two of
                                                                     these variables (“size” and “buffer”) are used by two different
4.1    Signature Extraction                                          functions, “malloc” and “bar”. Since variable “result” is not
4.1.1 Extracting Function Signature                                  used by any function, we do not analyze the taint propagation
Taint analysis is a program analysis technique used to detect        paths related to variable “result”. Therefore, we can extract
program vulnerabilities. Taint analysis focuses on sensitive         three <sources, sinks> tuples, namely <size, malloc>, <buffer,
data (e.g., user input) in the program, accurately tracing the       bar>, and <size, bar>. We analyze the propagation process
flow of data to pinpoint potential vulnerability points [36].        of each tuple, i.e., which operations each variable undergoes
The analysis of taint propagation is closely related to the          before ultimately propagating to the function use. For exam-
sensitivity of the information, and the flow of data reflects the    ple, variable “size” appears in the conditional statement of an
data dependency relationships, carrying a significant amount         “if ” statement and is then used by the “malloc” function. This
of semantic information in the code [21, 28, 37].                    completes the first taint propagation path for variable “size”,



USENIX Association                                                                         33rd USENIX Security Symposium                     1873
i.e., the first path in Figure 5. Then, variable “size” propa-      pute the similarity between the set of target function vectors
gates to the variable “buffer” through the return value of the      and the set of vulnerable function and patch function vectors,
“malloc” function, and it is ultimately used by the “bar” func-     respectively. Specifically, we compute the similarity of each
tion. This completes the second taint propagation path for the      path vector from the target function with all path vectors from
variable “size”, i.e., the third path in Figure 5.                  the vulnerable function and keep the highest similarity score.
   After extracting all taint propagation paths, we replace each    For example, if the vulnerable function has m paths, then one
node in the paths with the corresponding complete code line.        path of target function will calculate the similarity with the
For example, we use the statement “if (size <= 0)” from line        m paths of vulnerable function, thus obtaining m similarity
4 to replace the node “size <= 0” in the first path of Figure       scores and retaining the maximum value s1 . If the target func-
5. This results in the taint path, which is the signature of        tion has n paths, then there will be n similarity scores retained
the function. These taint paths constitute the signature of the     at the end, i.e., s1 , s2 , s3 ...... sn , and averaging these n values
function.                                                           gives the final similarity score S between the target function
4.1.2 Extracting Vulnerability and Patch Signatures                 and the vulnerable function. Since all the scores are combined
                                                                    in an averaging operation, they are not affected by the order
Similar to extracting taint paths for the target function, we
                                                                    in which the paths are combined.
also extract taint paths for both the vulnerabilities and patch
                                                                       Given the signature vectors set S f for each function in
functions. However, we do not utilize all paths, as most con-
                                                                    the target system, Sv for vulnerability signatures, and S p for
tent in vulnerabilities and patch functions is similar, with only
                                                                    patch signatures, we determine the presence of a vulnerability
a few lines of code being different. Therefore, we extract the
                                                                    in a target function based on the principle that its signature
differing parts, considering paths that are unique to vulnera-
                                                                    matches the vulnerability signature but not the patch signa-
bilities as vulnerability signatures and paths that are unique
                                                                    ture. Specifically, if the target function satisfies the following
to patches as patch signatures. The differential components
                                                                    condition, it possesses potential vulnerability:
represent critical features of vulnerabilities and precisely cap-
ture vulnerability elicitation and patching. Concentrating on           • C5: The target function should have a higher semantic
the differential paths helps in distinguishing between vulnera-           similarity to the vulnerable function, i.e., Sim (S f , Sv ) ≥
bilities and patches, mitigating the impact of identical paths.           Sim (S f , S p ).
The inputs to this phase are the potential vulnerabilities to be       In this paper, we employ cosine similarity to calculate the
verified and the pairs of vulnerability patch functions that are    similarity between signature vectors. Cosine similarity is a
similar to them, and the outputs are the target functions that      widely used algorithm for measuring similarity between vec-
are verified as vulnerabilities.                                    tors. Given two feature vectors A and B, their cosine similarity
                                                                    is defined as follow:
4.2    Vulnerability Detection
For the obtained function signatures, as well as the signa-                                                       A·B
                                                                                   Cosine_similarity (A, B) =                          (5)
tures of vulnerabilities and patches, we determine if the target                                                ∥A∥ · ∥B∥
function is vulnerable by comparing the similarity between            Here, A · B represents the dot product of A and B, and ∥A∥
signatures. Our signatures are composed of sets of paths, and       and ∥B∥ represent the Euclidean norms of A and B. C5 en-
each path is composed of code lines. Direct text comparison         sures the target function is more similar to the vulnerability
may lead to inaccurate similarity measurements due to minor         compared to the patch function, reducing the false positives
changes causing significant variations in similarity. In con-       where patches are incorrectly detected as vulnerabilities.
trast, using vector representations allows for a better capture
of the semantic information in the text, understanding the          5    Evaluation
meaning beyond mere reliance on vocabulary and surface              In this section, we evaluate the effectiveness of FIRE and aim
structure. In our approach, we use CodeBERT for the vector-         to address the following research questions:
ization of code lines. CodeBERT is pretrained on a large-scale         • RQ1: How accurate is FIRE compared to other advanced
code repository, providing a robust understanding of the se-              recurring vulnerability detection methods?
mantics of the code and enhancing the capture of semantic              • RQ2: How efficient is FIRE compared to other advanced
relationships between code lines [20].                                    recurring vulnerability detection methods?
   Therefore, we extract vector representations for all paths          • RQ3: How sensitive is FIRE in threshold selection?
contained in the obtained signatures. Specifically, for each           • RQ4: How do the multi-stage filters contribute to FIRE?
code line in a given path, we vectorize it to obtain a fixed-
                                                                       • RQ5: How does the tainted path contribute to FIRE?
length vector. Subsequently, the vectors corresponding to all
code lines in a path are averaged to reduce dimensionality             • RQ6: What is the performance of generic vulnerability
while maintaining uniformity in signature vector dimensions.              detection tools in detecting recurring vulnerabilities?
After such operation, each path is represented by a vector and         • RQ7: What is the performance of the code clone detec-
each function is represented by a set of vectors. Next, we com-           tion approach in detecting recurring vulnerabilities?



1874    33rd USENIX Security Symposium                                                                            USENIX Association
5.1    Evaluation Setup                                            we collect over 10,874 pairs of vulnerability-patch function
5.1.1 Dataset                                                      pairs (Fv , Fp ). Thus our vulnerability dataset contains 22,041
We select target systems for detection from the open-source        (11,167 + 10,874 = 22,041) pairs of vulnerability-patch func-
community, considering the following criteria during the se-       tions.
lection process: 1) Programming Language: The target sys-          5.1.2 Comparative Tools
tems should be popular C/C++ open-source projects, as our          To evaluate the effectiveness of FIRE, we compare it with two
method is primarily designed for vulnerability detection on        recurring vulnerability detection tools (i.e., VUDDY [29] and
C/C++; 2) Presence of Vulnerabilities: The target systems          MOVERY [53]), four general-purpose vulnerability detection
should contain a sufficient number of vulnerabilities to allow     tools (i.e., REVEAL [11], VulBERTa [23], Checkmarx [1],
for evaluating the effectiveness of FIRE and baseline methods      and FlawFinder [2]), and two general code clone detection
in detecting recurring vulnerabilities; 3) Diverse Application     tools (i.e., SourcererCC [43] and Lazar et al. [30]). VUDDY
Domains: The selected systems should cover various appli-          is an accurate and scalable tool for detecting recurring vul-
cation domains to demonstrate the generalizability of FIRE.        nerabilities, utilizing a length-filtering technique to reduce
Based on these criteria, we collect C/C++ repositories from        the number of signatures for comparison. MOVERY is an
GitHub with over 1,000 stars. From these projects, we select       accurate tool for detecting recurring vulnerabilities, consid-
the top 10 software in terms of release time for detection.        ering the oldest vulnerable functions that are susceptible to
Two software have less than two vulnerabilities detected by        attacks. REVEAL is a deep learning-based vulnerability de-
FIRE and our comparative recurring vulnerability detection         tection tool by using graph neural network. VulBERTa is a
tools (i.e., VUDDY [29] and MOVERY [53]). Therefore, we            method that utilizes deep knowledge representations to learn
exclude them and add two frequently detected software in           code syntax and semantics for detecting security vulnerabili-
the previous work [33, 34], SeaMonkey and Xen. Finally, we         ties in the source code. Checkmarx and FlawFinder are two
choose ten open-source projects, and the details are presented     traditional static analysis-based vulnerability detection tools.
in Table 5 in Appendix B in descending order of LOC. The           SourcererCC is a token-based code clone detector by com-
lines of code range from 490,103 to 15,573,896, showcasing         puting the overlapping similarities of two token sets. Lazar et
the scalability of FIRE. Application domains include inter-        al. design a novel code clone detector by analyzing the AST
net app suite, machine learning, database, emulator, scripting     similarity of two functions.
language, multimedia processing, computer vision, virtualiza-      5.1.3 Evaluation Metrics
tion, and image processing, which is diverse enough to show        We adopt five widely-used metrics, true positive (TP), false
the generalizability of FIRE.                                      positive (FP), false negative (FN), precision (P = T P/(T P +
   For the collection of our vulnerability dataset, we first use   FP)), and recall (R = T P/(T P + FN)) to evaluate the effec-
PatchDB [48] as our vulnerability dataset. PatchDB is the          tiveness of different methods. TPs and FPs are determined
most widely used vulnerability patch dataset available, which      through manual inspection by three security analysts of all
includes 11,167 security patches. However, PatchDB does not        vulnerability detection results. To ensure the reliability of
cover complete vulnerability data and the latest vulnerability     the vulnerability inspection results, we refer the source code
in PatchDB was discovered in 2019, so it does not include          of vulnerable functions and patch functions, NVD descrip-
new vulnerabilities that have emerged in the last five years.      tions, and issue descriptions during the inspection process.
Secondly, there are nearly six thousand security patches in        Detecting all vulnerabilities in the target program is almost
PatchDB that do not have a vulnerability type. We need more        impractical, making it difficult to measure the FNs of each tool
complete and updated vulnerability data with information           easily. Therefore, similar to the previous approaches [53, 56],
on vulnerability types. Therefore, we expand our vulnerabil-       we take the union of all TPs detected by three tools as the
ity dataset by manually collecting further vulnerability data.     ground truth (GT), serving as a benchmark to measure the
Similar to previous methods [31, 41], we check if the CVE          FNs of each tool. For example, the FNs in FIRE refer to the
contains a Git commit URL from the National Vulnerability          vulnerabilities detected by the other two methods but not dis-
Database (NVD). Subsequently, we collect these URLs to             covered by FIRE. The specific evaluation environments are
crawl the secure patch submissions for CVE vulnerabilities         in Appendix C.
from the respective Git repositories. Thus, we gather 3,316
C/C++ secure patches from the NVD. From these secure               5.2    Effectiveness Evaluation (RQ1)
patches, we extract vulnerable functions and patch functions.      We run VUDDY, MOVERY, and FIRE to detect recurring
Specifically, we focus on the header of the secure patch, which    vulnerabilities in the target projects. Among them, VUDDY
displays the file commits before and after the vulnerability       uses our collected vulnerability dataset, while MOVERY uses
is fixed [29, 56]. We extract all functions containing deleted     its own vulnerability dataset since it only discloses the vulner-
code lines from the vulnerability file as vulnerable functions     ability signatures without the code for signature generation.
(Fv ) and all functions containing added code lines from the       Table 1 presents the effectiveness of these three methods, with
patch file as patched functions (Fp ). After manual collection,    the second and third columns displaying the project name and



USENIX Association                                                                    33rd USENIX Security Symposium          1875
       Table 1: The True Positive, False Positive, False Negative, Precision, and Recall of VUDDY, MOVERY, and FIRE
                                           VUDDY                             MOVERY                                         FIRE
 IDX     Target System GT
                               TP FP     FN Precision Recall         TP FP FN Precision Recall              TP FP      FN     Precision Recall
 T1       FreeBSD        104   36 17     68 67.9%     34.6%          30 34 74 46.9%     28.8%               78 7       26     91.8%     75.0%
 T2      SeaMonkey       23    11 14     12 44.0%     47.8%          3   7 20 30.0%     13.0%               16 1       7      94.1%     69.6%
 T3       Turicreate     44    20 11     24 64.5%     45.5%          13 17 31 43.3%     29.5%               38 6       6      86.4%     86.4%
 T4      MongoDB         10    6   2     4   75.0%    60.0%          6   7   4   46.2%  60.0%               7   0      3      100.0% 70.0%
 T5         Xemu          7    4 21      3   16.0%    57.1%          0   2   7    0.0%   0.0%               4   1      3      80.0%     57.1%
 T6         PHP          10    3   4     7   42.9%    30.0%          2 13 8      13.3%  20.0%               7   0      3      100.0% 70.0%
 T7       OpenCV         127   74 11     53 87.1%     58.3%          49 29 78 62.8%     38.6%               101 3      26     97.1%     79.5%
 T8        FFmpeg         9    3   4     6   42.9%    33.3%          1   4   8   20.0%  11.1%               6   7      3      46.2%     66.7%
 T9          Xen          3    0   4     3    0.0%     0.0%          1   2   2   33.3%  33.3%               2   6      1      25.0%     66.7%
 T10     OpenMVG         48    20 0      28 100.0% 41.7%             12 4 36 75.0%      25.0%               39 2       9      95.1%     81.3%
 Total        -          385   177 88    208 66.8%    46.0%          117 119 268 49.6%  30.4%               298 33     87     90.0% 77.4%

the GT number of vulnerabilities, respectively. The remaining           tion of the dataset may influence the types of vulnerabilities
columns show the measurements for each tool.                            detected by FIRE, indicating the need to expand the dataset to
   Overall Results. FIRE achieves a detection precision                 cover a broader range of vulnerability types. Lastly, the preva-
of 90.0% for 298 recurring vulnerabilities with a recall of             lence of certain vulnerability types in real-world scenarios,
77.4%, missing 87 vulnerabilities. In contrast, VUDDY and               such as out-of-bounds write, may contribute to their higher
MOVERY detect only 177 and 117 recurring vulnerabilities,               detection numbers by FIRE.
with recall of 46% and 30.4%, precision of 66.8% and 49.6%,             1          if ( rc ) {
respectively, both inferior to FIRE. Overall, FIRE outperforms          2 +             if (s−>ops−>cleanup && s−>ctx.private) {
VUDDY and MOVERY in detecting recurring vulnerabilities,                3 +                   s−>ops−>cleanup(&s−>ctx);
                                                                        4 +            }
achieving an average improvement of 31.8% in precision and
                                                                        5               g_free (s−>tag);
39.2% in recall.                                                        6               g_free (s−>ctx. fs_root ) ;
   Vulnerability Types. We analyze the 298 vulnerabilities              7               v9fs_path_free (&path);
detected by FIRE. Among them, 38 vulnerabilities are Buffer             8          }
Overflow vulnerabilities (CWE-119), 37 vulnerabilities are In-                       List 1: A patch snippet for CVE-2016-9914
teger Overflow or Wraparound vulnerabilities (CWE-190), 28
vulnerabilities are Improper Input Validation vulnerabilities
                                                                        1          if ( rc ) {
(CWE-20), 17 vulnerabilities are Out-of-bounds Write vul-               2   *          v9fs_device_unrealize_common(s);
nerabilities (CWE-787), 15 vulnerabilities are Out-of-bounds            3          }
Read vulnerabilities (CWE-125), and 11 vulnerabilities are              4          v9fs_path_free (&path);
                                                                        5          return rc ;
Null Pointer Dereference vulnerabilities (CWE-476). This
indicates that FIRE is more proficient in detecting these six                   List 2: Part of Function v9fs_device_realize_common
types of vulnerabilities, while the number of other types of vul-
nerabilities detected by FIRE is relatively small. For example,         1 void v9fs_device_unrealize_common(V9fsState *s) {
CWE-399, CWE-834, CWE-434, CWE-362, and CWE-326,                        2      if (s−>ops && s−>ops−>cleanup) {
etc. Several factors contribute to this phenomenon. Firstly,            3           s−>ops−>cleanup(&s−>ctx);
the critical features selected for vulnerability detection may          4      }
                                                                        5       ...
exhibit biases towards certain types of vulnerabilities, mak-           6      g_free (s−>tag);
ing FIRE more proficient in detecting them. For example,                7       ...
including formatting strings and memory allocation functions            8      g_free (s−>ctx. fs_root ) ;
                                                                        9 }
enhances the detection of buffer overflow vulnerabilities. Our
use of sensitive APIs such as “copy”, “sizeof ”, and our focus                    List 3: Function v9fs_device_unrealize_common
on pointers make FIRE proficient in detecting Out-of-bounds
Write and Read vulnerabilities. Similarly, the lack of con-                False Positive Analysis for FIRE. We analyze all 33 false
sideration for file reading-related functions such as “Create-          positives in the experimental results and identify two main
File” and “WriteFile” limits the detection of vulnerabilities of        reasons. The first one is patch fixes extending beyond the
CWE-434. Additionally, FIRE also has limitations in detect-             function granularity, which is also one of the reasons for false
ing vulnerabilities that are difficult to detect through sensitive      positives in VUDDY and MOVERY. For example, the patch
APIs or keywords, such as CWE-326. Secondly, some types of              for CVE-2016-9914 shown in List 1 is a denial of service vul-
vulnerable functions have lower similarity to patch functions,          nerability due to a missing cleanup operation. The patch adds
thus can be better distinguished. Additionally, the composi-            the “s->ops->cleanup()” function for the cleanup operation.



1876     33rd USENIX Security Symposium                                                                                   USENIX Association
FIRE determines the function in List 2 as a vulnerability due              otherwise, it is filtered out. However, when the target function
to the absence of the lines introduced by patch and its high               undergoes significant changes, this method may still result in
similarity to the vulnerable function. However, the function               some false negatives. For example, List 4 shows the added
“v9fs_device_unrealize_common” (shown in List 3) called in                 line statements in CVE-2018-14567, where the “return -1”
List 2 actually implements the patched functionality. In situ-             statement appears eight times in the vulnerable function, nine
ations where the patch functionality is implemented outside                times in the patch function, and nine times in a target function.
the function, FIRE encounters false positives as it cannot con-            In this scenario, even if the target function has not been fixed,
clusively determine whether a vulnerability has been fixed.                it may still be filtered out due to the mismatch in added line
While inter-procedural analysis could potentially alleviate                counts, resulting in false negatives.
this issue, it comes at the cost of increased computational
                                                                           1          return −1;
overhead, thereby compromising the efficiency of FIRE.                     2      }
   The second reason is caused by the similarity of vulner-                3 +    if (( state −>how != GZIP) && (ret != LZMA_OK) && (ret
abilities, a phenomenon also observed in MOVERY, result-                           != LZMA_STREAM_END)) {
                                                                           4 +        xz_error ( state , ret , "lzma error ") ;
ing in a substantial number of false positives. For instance,
                                                                           5 +        return −1;
CVE-2016-8654 2 encompasses three vulnerable functions                     6 +    }
(i.e., “jpc_qmfb_split_col”, “jpc_qmfb_split_colgrp”, and                  7   } while (strm−>avail_out && ret != LZMA_STREAM_END);
“jpc_qmfb_split_colres”) that are highly similar, all address-
                                                                                   List 4: A patch snippet for CVE-2018-14567
ing heap buffer overflow vulnerabilities and fixing them by
adjusting the allocated buffer size. When the target function is
                                                                              The third reason is that we apply LOC filtering to filter
a clone of one vulnerability (e.g., “jpc_qmfb_split_colgrp”), it
                                                                           out all target functions with fewer than five lines of code,
exhibits high similarity with the other two vulnerabilities (i.e.,
                                                                           leading to some false negatives. However, the LOC filtering
“jpc_qmfb_split_col” and “jpc_qmfb_split_colres”), leading
                                                                           also resulted in the exclusion of numerous short functions,
to false positives. This situation can be mitigated by restrict-
                                                                           significantly enhancing our efficiency (refer to Section 5.5).
ing the target function to match only the vulnerability with
the highest similarity within the same CVE. This modifica-                    Due to space limitations, the false positive and false neg-
tion addresses the majority of false positives, but there is a             ative analysis for VUDDY and MOVERY are presented in
specific scenario that remains unresolved. In cases where                  Appendix D.
the target function introduces changes to deleted lines that               5.3    Efficiency Evaluation (RQ2)
do not impact the triggering of vulnerabilities, the condi-                To evaluate the efficiency of FIRE, we measure the time over-
tions for deleted lines (C1) may not be satisfied. As a result,            head of FIRE, VUDDY, and MOVERY in detecting vulnera-
false negatives may occur with genuine vulnerabilities (i.e.,              bilities across ten target software projects. These tools share
“jpc_qmfb_split_colgrp”), while false positives may arise with             similar processes with FIRE, including extracting vulnerabil-
similar vulnerabilities (i.e., “jpc_qmfb_split_colres”).                   ity or patch signatures, extracting target function signatures,
   False Negative Analysis for FIRE. We analyze the 87                     and matching. As the codes for generating vulnerability and
false negatives in the experimental results and categorize their           patch signatures of MOVERY are not open-source, we can not
causes into three types. The first reason is as mentioned in the           measure the time spent on this operation. Additionally, consid-
false positive analysis, where the target functions underwent              ering that the generation of vulnerability and patch signatures
changes on deleted lines that do not affect the vulnerability              is an one-time operation, we pre-generate all the required
triggering. This leads to conditions on deleted lines (C1) not             vulnerability signatures and cache down them. Therefore, we
being satisfied, preventing them from entering the judgment                only record the time for target function signature generation
of AST filtering and taint analysis, resulting in false negatives.         and matching, in other words, the time from the beginning to
   The second reason is that there are frequently occurring                the end of the detection process.
statements in Sadd , such as return statements. These state-                  The time overhead of each tool is recorded in Figure 6,
ments may often appear in the target functions, making them                where the x-axis is arranged from small to large according to
not satisfy our detection criteria for added lines (C2). As a              the number of code lines in the target software, and the y-axis
result, they cannot proceed to AST filtering and taint analysis,           represents the time overhead in seconds. Overall, the time
leading to a significant number of false negatives. To address             overhead of all tools except T5 (PHP) increases with the size
this issue, we count the occurrences of Sadd in target functions,          of the project. This is because despite having more lines of
vulnerable functions, and patch functions. If the statement                code, PHP parses out fewer functions, and therefore its detec-
counts in the target function match those in the vulnerable                tion is relatively faster. Among the three tools, VUDDY has
function, the target function can proceed to the next stage,               the least detection time because it simply extracts functions
    2 Due to the large amount of code, we provide the commit link          from files and performs normalization and abstraction opera-
for CVE-2016-8654: https://github.com/jasper-software/jasper/commit/4a59   tions. Since it does not consider any semantic information, its
cfaf9ab3d48fca4a15c0d2674bf7138e3d1a                                       speed is faster.



USENIX Association                                                                            33rd USENIX Security Symposium          1877
                                           Table 2: The effectiveness and efficiency of FIRE as thresholds change
                              T1                        0.6                             0.7                              0.8
                              T2             0.6        0.7       0.8       0.6         0.7        0.8        0.6        0.7        0.8
                        Total F1 Score     82.46%     80.94%    76.26%    82.62%      81.69%     76.42%     80.38%     80.33%     76.26%
                         Speed (loc/s)     5,264.9    5,563.7   6,207.7   5,889.6     6,193.6    7,021.8    7,161.1    7,120.7    7,759.6


                 4000         VUDDY                                                 5.4    Threshold Sensitivity Analysis (RQ3)
                 3500         MOVERY                                                In the filtering stage, we can achieve a balance between ef-
                              FIRE
                 3000                                                               fectiveness and recall by configuring two thresholds. One is
  Overhead (s)




                 2500                                                               the threshold for token filtering (i.e., T1 ), and the other is the
                 2000                                                               threshold for AST filtering (i.e., T2 ). Our default configuration
                 1500                                                               is set to 0.7 for T1 and 0.6 for T2 , and we use these settings
                 1000                                                               for the effectiveness experiments in Section 5.2. In this part,
                  500                                                               we evaluate the sensitivity of FIRE to the two thresholds in
                    0                                                               terms of effectiveness and efficiency. For each threshold, we
                          T10 T9 T8 T7 T6 T5 T4 T3 T2 T1                            select three values: 0.6, 0.7, and 0.8, resulting in a total of
                                         Target Software                            nine threshold combinations. For each combination, we run
Figure 6: The time overhead of VUDDY, MOVERY, and FIRE                              FIRE on ten target software projects, recording the overall F1
   Compared to MOVERY, which also considers data flow and                           score as a measure of effectiveness and the average lines of
control flow information, our detection speed is faster. This is                    code processed per second as a measure of efficiency.
because MOVERY requires semantic analysis of functions to                              The experimental data in Table 2 shows that when both
generate signatures by extracting data flow and control flow                        thresholds are set to 0.8, the F1 score is slightly lower. This
and matching them at line granularity. Although MOVERY                              is because the strict filtering conditions result in more false
also reduces the search scope by taking the measure of com-                         negatives, leading to a decrease in recall. Choosing thresh-
paring path information, it can only reduce roughly half of                         olds of 0.7 or 0.6 has little impact on the F1 score, both
the search space from the software codebase. FIRE can re-                           achieving around 80%. The default configuration achieves
duce 99.96% (discussed in RQ4) of the search space through                          the highest F1 scores. Compared to the 0.6 for both T1 and T2
the multiple filtering approach, and therefore achieves higher                      configuration (0.6-0.6), which have almost the same F1 score,
efficiency. The exception is T3 (Turicreate), which is due to                       the default configuration is faster, processing an average of
the fact that T3 has more vulnerabilities, which means that                         5,889.6 lines of code per second. Therefore, we consider the
more candidate functions enter the taint analysis phase. Taint                      default configuration to be a better choice.
analysis consumes more time, so T3 is slower to detect. When                        5.5    Contribution of Multi-Stage Filter (RQ4)
there are a large number of vulnerabilities in the software, the                    In order to achieve high efficiency, we add multi-stage filter
speed of detection decreases, which is the limitation of FIRE                       to FIRE. In this part, we explore the effectiveness of each
in terms of efficiency.                                                             filtering step by analyzing its speed, normal function filtering
   In addition, as shown in Figure 6, when the target program                       rate, and vulnerability detection recall, where the filtering
changes from a small program to a large program, the in-                            speed is the average number of functions processed per second
crease in our time overhead is more moderate and does not                           in each stage. The normal function filtering rate is calculated
increase rapidly compared to MOVERY. For example, T10                               by dividing the number of remaining functions at the end
(OpenMVG) is the smallest program among the ten target                              of each stage by the overall number of functions. As for the
programs with 490,103 lines of code, and T1 (FreeBSD) is                            vulnerability detection recall, we inspect 385 GT instances
the largest program with 15,573,896 lines of code, which is                         after each phase and derive the recall by dividing the number
31.77 times the program size of T10. The detection time of                          of remaining GT instances in each phase by the number of
FIRE for T1 is only 4.22 times longer than that of T10. As                          instances in the previous phase. The percentages represent
a comparison, the detection time of MOVERY for T1 is 93                             the combined percentages across all projects.
times longer than that of T10, and VUDDY is also 45.51 times                            First of all, only 6.63% of the functions in the vulnerability
longer. These data clearly prove that FIRE can effectively re-                      dataset have less than five lines of code. Among the software
duce the detection time of large software, and this advantage                       to be inspected, about 30.96% of the functions have less than
is more obvious as the size of the program increases. Even                          5 lines of code in PHP and 21.59% in FFmpeg. Therefore, it
with a project size of 38.6 M code lines, we can still complete                     makes sense to improve efficiency by discarding functions
the detection in less than two hours. This indicates that FIRE                      with less than five LOC in the processing phase.
can scale to large software projects, meeting practical needs                           With the second row of Table 3, we can get that SFBF can
in real-world applications.                                                         filter 80.63% of target functions, the Token Filter further fil-



1878              33rd USENIX Security Symposium                                                                                 USENIX Association
ters out 99.82% of functions, and after the AST Filter, 99.96%      5.6    Contribution of Taint Analysis (RQ5)
of functions are filtered. For instance, the number of functions    In the Vulnerability Identification Phase, we perform vul-
extracted from files in FFmpeg is 23,315. After SFBF, only          nerability identification in three steps: extracting taint paths,
7,737 functions remain, and after the Token Filter, only 308        embedding the paths as vectors using CodeBERT, and com-
functions are retained. The final AST Filter further reduces        puting similarities. To assess the effectiveness of using taint
the number of functions to 15. It can be observed that the          paths, we conduct two ablation experiments. In the first exper-
number of functions retained after each filtering layer sig-        iment, we remove the initial step (i.e., without extracting the
nificantly decreases for each software, indicating that each        taint paths) and directly extract vectors using CodeBERT. In
filtering layer we set up plays a role. The fact that only 0.04%    the second experiment, we entirely remove the Vulnerability
of the final functions need to extract taint paths indicates that   Identification Phase and label all the target functions filtered
the multi-step filtering is able to massively reduce the number     by the AST as vulnerabilities.
of functions to be detected, allowing us to keep the overall           For the first ablation experiment, we select all functions
speed up despite the relatively slow extraction of taint paths      (i.e., 359 functions) that pass the AST Filter for CodeBERT
(only 0.12 functions per second).                                   to analyze. Out of the 298 TPs detected by FIRE, CodeBERT
                                                                    is able to detect only 257. This means there are 41 instances
Table 3: The speed and proportion of functions that can be          that CodeBERT misses, resulting in 41 FNs. Additionally,
filtered at each filter                                             CodeBERT produces 14 more FPs than FIRE. These findings
                    Bloom      Token      AST      Taint Path       indicate that taint analysis provides benefits for FIRE, en-
   Filtering Rate   80.63%    99.82%     99.96%     99.97%          abling it to detect more vulnerabilities with higher precision.
       Recall       93.24%    99.27%     91.97%     99.99%             For the second ablation experiment, the experimental data
    Speed (f/s)     167.71     54.31      1.43        0.12          indicates that by extracting signatures through taint paths,
                                                                    FIRE can eliminate 14 FPs. These eliminated FPs primarily
   By looking at the third row of Table 3, we can see that each     include two types: 1) Target functions that added semanti-
stage produces a certain percentage of FNs, with the SFBF           cally equivalent statements to patch the vulnerabilities, and
and the AST Filter producing more FNs. The reason for gener-        2) Patches fix vulnerabilities by changing the order of state-
ating FNs in the SFBF stage is the incomplete and imprecise         ments, which AST cannot distinguish between vulnerability
vulnerability features. As analyzed in RQ1, the vulnerability       and patch functions.
features have a mapping relationship with the vulnerability            For example, the patch in List 7 in Appendix E addresses a
types. The lack of vulnerability features focusing on certain       vulnerability related to unauthorized information disclosure.
vulnerability types generates FNs. In addition, the vulnerabil-     The target function in List 8 in Appendix E achieves seman-
ity features contain the full range of C/C+ keywords, which         tically equivalent patching through two nested if statements.
differ in their ability to characterise whether a function is a     Through the extraction of data flow, the use of taint paths can
vulnerability or not. The introduction of low-capability key-       effectively address such semantically equivalent alternatives,
words can be disruptive to vulnerability judgment. In our           identifying semantic equivalence between the target function
future work, we will further investigate the vulnerability fea-     and patch function, thereby reducing FPs. The patch in List 9
tures to extract more comprehensive and precise vulnerability       in Appendix E solves the issue of mismatched assumptions by
features to reduce FNs. The main reason for FN in the AST           swapping the order of code blocks. This change is reflected
Filter phase is the checking of added and deleted lines, too        as a positional shift of subtrees in the AST and does not alter
strict judgments will bring FNs as analyzed in RQ1. Over-           the number or content of nodes. Therefore, using AST simi-
all, the filtering phase does add some FNs, but brings more         larity filter is insufficient to distinguish differences between
massive improvements in detection efficiency. The filtering         the vulnerable function and the patched function, leading to
phase makes sense from the perspective of balancing recall          a misclassification of the target function as a vulnerability.
and time overhead.                                                  Taint paths can highlight the order of variable occurrences,
   Moreover, we also investigate the effectiveness of SFBF          allowing them to identify differences between vulnerability
in improving the detection of vulnerabilities. Specifically, we     and patch, thus eliminating FPs.
replace the SFBF with a standard Bloom Filter in FIRE and
then count the number of GT reported. The result reveals that       5.7 Performance of General-Purpose Vulnera-
only 142 out of 385 GT vulnerabilities are reported, resulting          bility Detection (RQ6)
in a recall of only 36.9%. By employing the SFBF, we are            Compare with REVEAL and VulBERTa. We train the mod-
able to detect an additional 156 recurring vulnerabilities, thus    els of REVEAL and VulBERTa using the Diversevul dataset
increasing the recall by 40.5%. This phenomenon demon-              [13]. 385 GTs are used as the test set to assess their detection
strates that our SFBF can tolerate certain modifications to         performance. We do not use all functions from the ten target
functions through shuffling and discarding, thereby fulfilling      software as the test dataset because analyzing all functions
the requirements for approximate member queries.                    from predictions is a challenging and time-consuming task.



USENIX Association                                                                     33rd USENIX Security Symposium          1879
The test results reveal that, out of the 385 GTs, REVEAL only        Only when the similarity between a target function and a
detects 134, with a recall of 34.8%, while VulBERTa can de-          vulnerability is higher and surpasses a threshold is the target
tect 158, with a recall of 41%. Our method achieves a 77.4%          function considered a potential vulnerability. Therefore, this
recall in detecting the 298 GTs, outperforming the two deep          approach is challenged in detecting extensive modifications
learning-based methods. This is because the performance of           in target functions that preserve the semantic equivalence
deep learning-based methods relies on the model architec-            with vulnerabilities, necessitating the assistance of dynamic
ture and the training dataset, especially on the quantity and        analysis techniques. However, this could have a substantial
correctness of the labeled dataset. However, the intelligent col-    impact on our efficiency. This reason also leads us to remain
lection, labeling, and classification of vulnerability datasets      limited in dealing with similar vulnerabilities. We mitigate
still present challenges [38]. Therefore, our method proves to       this issue by restricting target functions to match only the
be more effective in detecting recurring vulnerabilities.            most similar vulnerabilities with the same CVE. However,
   Compare with FlawFinder and Checkmarx. We use                     there are still specific cases that remain unresolved as we
two static analysis tools to inspect vulnerabilities in ten soft-    discussed in Section 5.2.
ware to see if they could detect the 385 GTs. Among them,               Secondly, as mentioned in our FN analysis, we filter target
FlawFinder only detects 44 vulnerabilities, while Checkmarx          functions by checking for the presence of deleted lines in the
detects 50 vulnerabilities. With recall of only 11.4% and            target function. This filtering approach may be too strict and
13%, respectively, they lag far behind FIRE, VUDDY, and              could miss potential vulnerabilities where modifications are
MOVERY. These results indicate that static analysis is inade-        made to the deleted lines. In future work, we plan to adjust
quate for detecting recurring vulnerabilities, confirming the        the criteria for judging added and deleted lines to tolerate a
effectiveness of our method.                                         certain degree of modification.
                                                                        Thirdly, our method is designed for vulnerabilities that
5.8    Performance of Clone Detection (RQ7)                          occur at the function level. Therefore, any changes beyond
In this part, we examine the ability of general code clone           the function level cannot be handled. This limitation leads to
detection tools to detect recurring vulnerabilities. Specifically,   FPs and FNs. Implementing inter-procedural analysis could
we select two state-of-the-art code clone detectors, Sourcer-        mitigate this issue. However, inter-procedural analysis comes
erCC [43] and the tool developed by Lazar et al. [30], as            with higher computational costs.
comparative tools. We use the full vulnerability dataset as             Lastly, there are limitations to the generalizability of FIRE
input, treating functions similar to these vulnerable functions      to other programming languages and vulnerabilities. Since
in each project as potential vulnerabilities. SourcererCC and        FIRE only targets C/C++ when selecting crucial features, this
Lazar et al. report 35,127 and 17,839 potential vulnerabili-         results in FIRE only being able to detect vulnerabilities in
ties, respectively. We manually analyze 10% of the randomly          C/C++. In the future, we will extract corresponding keywords
selected results. The analysis shows that SourcererCC and            for other programming languages so that FIRE can be ported
Lazar et al. have a precision of 0.72% and 0.46%, respectively.      to other programming languages. The lack of vulnerability
Additionally, we use these two tools to detect 385 GTs to cal-       profiles for certain types of vulnerabilities may limit FIRE
culate recall. The results show that the recall of SourcererCC       to extend to other vulnerability types. In the future, we will
and Lazar et al. are 41.9% and 36.7%, respectively. These            further investigate the vulnerability features to extract more
results indicate that general code clone detection methods are       comprehensive and precise features to reduce FNs.
not suitable for detecting recurring vulnerabilities. In most
cases, the code differences between vulnerable functions and         7   Conclusion
patched functions are minimal. Therefore, code clone detec-          In this paper, we propose and implement a novel method
tion tools that use only vulnerable functions may incorrectly        named FIRE. FIRE can 1) rapidly detect extensive recur-
identify patched functions as vulnerable, resulting in high FPs.     ring vulnerabilities through multi-stage filtering, 2) support
                                                                     for detecting complex recurring vulnerabilities with syntax
                                                                     changes, and 3) consider differences between vulnerabilities
6     Discussion                                                     and patches by using differential taint paths. Our evaluation
Vulnerability Disclosure. Of the 298 vulnerabilities we iden-        results demonstrate that FIRE significantly outperforms state-
tified, 13 vulnerabilities are successfully replicated. We report    of-the-art methods for recurring vulnerability detection. It
these vulnerabilities to the respective software development         can detect 298 recurring vulnerabilities, achieving an average
teams. Among them, eight development teams confirm our               improvement of 31.8% in precision and 39.2% in recall.
findings, while we are still awaiting responses from the re-
maining. For the vulnerabilities that have not been confirmed,       Acknowledgements
we will not disclose any information until patches are applied.      We would thank the anonymous reviewers for their insightful
    Limitations. Our method still has some limitations: Firstly,     comments to improve the quality of the paper. This work
we detect vulnerabilities by computing the similarity between        is supported by the Key Program of the National Science
target functions and both vulnerability and patch functions.         Foundation of China under Grant No. U2336203.



1880    33rd USENIX Security Symposium                                                                        USENIX Association
References                                                                        of the IEEE/ACM 46th International Conference on Software
                                                                                  Engineering (2024), pp. 1–13.
 [1] Checkmarx. https://checkmarx.com/, 2024.                                [19] F ENG , W., K ANDLUR , D. D., S AHA , D., AND S HIN , K. G.
 [2] Flawfinder. https://dwheeler.com/flawfinder/, 2024.                          Stochastic fair blue: A queue management algorithm for en-
 [3] A parser generator tool and a incremental parsing library.                   forcing fairness. In Proceedings of the 20th Annual Joint Con-
     https://tree-sitter.github.io/tree-sitter/, 2024.                            ference of the IEEE Computer and Communications Society
 [4] Universal ctags. https://github.com/universal-ctags/                         (2001), pp. 1520–1529.
     ctags/, 2024.                                                           [20] F ENG , Z., G UO , D., TANG , D., D UAN , N., F ENG , X., G ONG ,
 [5] BABI Ć , D., M ARTIGNONI , L., M C C AMANT, S., AND S ONG ,                 M., S HOU , L., Q IN , B., L IU , T., J IANG , D., AND Z HOU ,
     D. Statically-directed dynamic automated test generation. In                 M. Codebert: A pre-trained model for programming and nat-
     Proceedings of the 2011 ACM SIGSOFT International Sympo-                     ural languages. In Proceedings of the 2020 Conference on
     sium on Software Testing and Analysis (2011), pp. 12–22.                     Empirical Methods in Natural Language Processing (2020),
 [6] BABOESCU , F., AND VARGHESE , G. Scalable packet classifi-                   pp. 1536–1547.
     cation. ACM SIGCOMM Computer Communication Review                       [21] F ENG , Z., WANG , Z., D ONG , W., AND C HANG , R. Bintaint:
     31, 4 (2001), 199–210.                                                       a static taint analysis method for binary vulnerability mining.
 [7] B ÖHME , M., P HAM , V., AND ROYCHOUDHURY, A. Coverage-                      In Proceedings of the 2018 International Conference on Cloud
     based greybox fuzzing as markov chain. In Proceedings of the                 Computing, Big Data and Blockchain (2018), pp. 1–8.
     2016 ACM SIGSAC Conference on Computer and Communi-                     [22] G ODEFROID , P., L EVIN , M. Y., AND M OLNAR , D. A. Au-
     cations Security (2016), pp. 1032–1043.                                      tomated whitebox fuzz testing. In Proceedings of the 2008
 [8] B OWMAN , B., AND H UANG , H. H. Vgraph: A robust vulner-                    Annual Network and Distributed System Security Symposium
     able code clone detection system using code property triplets.               (2008), pp. 151–166.
     In Proceedings of the 2020 IEEE European Symposium on                   [23] H ANIF, H., AND M AFFEIS , S. Vulberta: Simplified source
     Security and Privacy (2020), pp. 53–69.                                      code pre-training for vulnerability detection. In Proceedings of
 [9] B RODER , A., AND M ITZENMACHER , M. Using multiple hash                     the 2022 International Joint Conference on Neural Networks
     functions to improve ip lookups. In Proceedings of the 20th                  (2022), pp. 1–8.
     Annual Joint Conference of the IEEE Computer and Communi-               [24] H U , T., X U , Z., FANG , Y., W U , Y., Y UAN , B., Z OU , D., AND
     cations Society (2001), pp. 1454–1463.                                       J IN , H. Fine-grained code clone detection with block-based
[10] C HA , S. K., W OO , M., AND B RUMLEY, D. Program-adaptive                   splitting of abstract syntax tree. In Proceedings of the 32nd
     mutational fuzzing. In Proceedings of the 2015 IEEE Sympo-                   ACM SIGSOFT International Symposium on Software Testing
     sium on Security and Privacy (2015), pp. 725–741.                            and Analysis (2023), pp. 89–100.
[11] C HAKRABORTY, S., K RISHNA , R., D ING , Y., AND R AY, B.               [25] H U , Y., Z OU , D., P ENG , J., W U , Y., S HAN , J., AND J IN , H.
     Deep learning based vulnerability detection: Are we there                    Treecen: Building tree graph for scalable semantic code clone
     yet. IEEE Transactions on Software Engineering 48, 9 (2022),                 detection. In Proceedings of the 37th IEEE/ACM International
     3280–3296.                                                                   Conference on Automated Software Engineering (2022), pp. 1–
[12] C HEN , H., X UE , Y., L I , Y., C HEN , B., X IE , X., W U , X.,            12.
     AND L IU , Y. Hawkeye: Towards a desired directed grey-box              [26] H UANG , Z., DANGELO , M., M IYANI , D., AND L IE , D. Ta-
     fuzzer. In Proceedings of the 2018 ACM SIGSAC Conference                     los: Neutralizing vulnerabilities with security workarounds for
     on Computer and Communications Security (2018), pp. 2095–                    rapid response. In Proceedings of the 2016 IEEE Symposium
     2108.                                                                        on Security and Privacy (2016), pp. 618–635.
[13] C HEN , Y., D ING , Z., A LOWAIN , L., C HEN , X., AND WAG -            [27] JANG , J., AGRAWAL , A., AND B RUMLEY, D. Redebug: find-
     NER , D. Diversevul: A new vulnerable source code dataset for                ing unpatched code clones in entire os distributions. In Pro-
     deep learning based vulnerability detection. In Proceedings                  ceedings of the 2012 IEEE Symposium on Security and Privacy
     of the 26th International Symposium on Research in Attacks,                  (2012), pp. 48–62.
     Intrusions and Defenses (2023), pp. 654–668.                            [28] K ANG , W., S ON , B., AND H EO , K. Tracer: signature-based
[14] C HEN , Y., Z HANG , Y., WANG , Z., X IA , L., BAO , C., AND                 static analysis for detecting recurring vulnerabilities. In Pro-
     W EI , T. Adaptive android kernel live patching. In Proceedings              ceedings of the 2022 ACM SIGSAC Conference on Computer
     of the 26th USENIX Security Symposium (2017), pp. 1253–                      and Communications Security (2022), pp. 1695–1708.
     1270.                                                                   [29] K IM , S., W OO , S., L EE , H., AND O H , H. Vuddy: A scalable
[15] C UI , W., P EINADO , M., WANG , H. J., AND L OCASTO , M. E.                 approach for vulnerable code clone discovery. In Proceedings
     Shieldgen: Automatic data patch generation for unknown vul-                  of the 2017 IEEE Symposium on Security and Privacy (2017),
     nerabilities with informed probing. In Proceedings of the 2007               pp. 595–614.
     IEEE Symposium on Security and Privacy (2007), pp. 252–266.             [30] L AZAR , F., AND BANIAS , O. Clone detection algorithm based
[16] D HARMAPURIKAR , S., K RISHNAMURTHY, P., AND TAYLOR ,                        on the abstract syntax tree approach. In Proceedings of the
     D. E. Longest prefix matching using bloom filters. In Proceed-               9th IEEE International Symposium on Applied Computational
     ings of the 2003 Conference on Applications, Technologies,                   Intelligence and Informatics (2014), pp. 73–78.
     Architectures, and Protocols for Computer Communications                [31] L I , F., AND PAXSON , V. A large-scale empirical study of
     (2003), pp. 201–212.                                                         security patches. In Proceedings of the 2017 ACM SIGSAC
[17] D U , X., C HEN , B., L I , Y., G UO , J., Z HOU , Y., L IU , Y., AND        Conference on Computer and Communications Security (2017),
     J IANG , Y. Leopard: Identifying vulnerable code for vulner-                 pp. 2201–2215.
     ability assessment through program metrics. In Proceedings              [32] L I , Y., X UE , Y., C HEN , H., W U , X., Z HANG , C., X IE , X.,
     of the IEEE/ACM 41st International Conference on Software                    WANG , H., AND L IU , Y. Cerebro: context-aware adaptive
     Engineering (2019), pp. 60–71.                                               fuzzing for effective vulnerability detection. In Proceedings of
[18] F ENG , S., S UO , W., W U , Y., Z OU , D., L IU , Y., AND J IN ,            the 27th ACM Joint Meeting on European Software Engineer-
     H. Machine learning is all you need: A simple token-based                    ing Conference and Symposium on the Foundations of Software
     approach for effective code clone detection. In Proceedings                  Engineering (2019), pp. 533–544.




USENIX Association                                                                                33rd USENIX Security Symposium               1881
[33] L I , Z., Z OU , D., X U , S., J IN , H., Z HU , Y., AND C HEN , Z.           Conference (2000), pp. 257–267.
     Sysevr: A framework for using deep learning to detect software           [47] WANG , S., WANG , X., S UN , K., JAJODIA , S., WANG , H.,
     vulnerabilities. IEEE Transactions on Dependable and Secure                   AND L I , Q. Graphspd: Graph-based security patch detection
     Computing 19, 4 (2021), 2244–2258.                                            with enriched code semantics. In Proceedings of the 2023 IEEE
[34] L I , Z., Z OU , D., X U , S., O U , X., J IN , H., WANG , S., D ENG ,        Symposium on Security and Privacy (2023), pp. 2409–2426.
     Z., AND Z HONG , Y. Vuldeepecker: A deep learning-based                  [48] WANG , X., WANG , S., F ENG , P., S UN , K., AND JAJODIA , S.
     system for vulnerability detection. In Proceedings of the 2018                Patchdb: A large-scale security patch dataset. In Proceedings
     Annual Network and Distributed System Security Symposium                      of the 51st Annual IEEE/IFIP International Conference on
     (2018), pp. 1–15.                                                             Dependable Systems and Networks (2021), pp. 149–160.
[35] L IVSHITS , V. B., AND L AM , M. S. Finding security vulner-             [49] WANG , X., WANG , S., S UN , K., BATCHELLER , A., AND JA -
     abilities in java applications with static analysis. In Proceed-              JODIA , S. A machine learning approach to classify security
     ings of the 2005 USENIX Security Symposium (2005), vol. 14,                   patches into vulnerability types. In Proceedings of the 2020
     pp. 271–286.                                                                  IEEE Conference on Communications and Network Security
[36] N EWSOME , J., AND S ONG , D. X. Dynamic taint analysis                       (2020), pp. 1–9.
     for automatic detection, analysis, and signature generation of           [50] WANG , Y., Y E , Y., W U , Y., Z HANG , W., X UE , Y., AND L IU ,
     exploits on commodity software. In Proceedings of the 2005                    Y. Comparison and evaluation of clone detection techniques
     Annual Network and Distributed System Security Symposium                      with different code representations. In Proceedings of the
     (2005), pp. 2–43.                                                             IEEE/ACM 45th International Conference on Software Engi-
[37] N IU , W., Z HANG , X., D U , X., Z HAO , L., C AO , R., AND                  neering (2023), pp. 332–344.
     G UIZANI , M. A deep learning based static taint analysis                [51] W OO , M., C HA , S. K., G OTTLIEB , S., AND B RUMLEY, D.
     approach for iot software vulnerability location. Measurement                 Scheduling black-box mutational fuzzing. In Proceedings of
     152 (2020), 1–12.                                                             the 2013 ACM SIGSAC Conference on Computer and Commu-
[38] N ONG , Y., O U , Y., P RADEL , M., C HEN , F., AND C AI , H.                 nications Security (2013), pp. 511–522.
     Generating realistic vulnerabilities via neural code editing: an         [52] W OO , S., C HOI , E., L EE , H., AND O H , H. V1scan: Dis-
     empirical study. In Proceedings of the 30th ACM Joint Meet-                   covering 1-day vulnerabilities in reused c/c++ open-source
     ing on European Software Engineering Conference and Sym-                      software components using code classification techniques. In
     posium on the Foundations of Software Engineering (2022),                     Proceedings of the 32nd USENIX Security Symposium (2023),
     pp. 1097–1109.                                                                pp. 6541–6556.
[39] PAGH , A., PAGH , R., AND R AO , S. S. An optimal bloom filter           [53] W OO , S., H ONG , H., C HOI , E., AND L EE , H. Movery: A
     replacement. In Proceedings of the 16th Annual ACM-SIAM                       precise approach for modified vulnerable code clone discovery
     Symposium on Discrete Algorithms (2005), pp. 823–829.                         from modified open-source software components. In Proceed-
[40] P ERKINS , J. H., K IM , S., L ARSEN , S., A MARASINGHE , S.,                 ings of the 31st USENIX Security Symposium (2022), pp. 3037–
     BACHRACH , J., C ARBIN , M., PACHECO , C., S HERWOOD ,                        3053.
     F., S IDIROGLOU , S., S ULLIVAN , G., W ONG , W., Z IBIN , Y.,           [54] W OO , S., L EE , D., PARK , S., L EE , H., AND D IETRICH , S.
     E RNST, M. D., AND R INARD , M. Automatically patching er-                    V0finder: Discovering the correct origin of publicly reported
     rors in deployed software. In Proceedings of the ACM SIGOPS                   software vulnerabilities. In Proceedings of the 30th USENIX
     22nd Symposium on Operating Systems Principles (2009),                        Security Symposium (2021), pp. 3041–3058.
     pp. 87–102.                                                              [55] W U , Y., F ENG , S., Z OU , D., AND J IN , H. Detecting semantic
[41] P ERL , H., D ECHAND , S., S MITH , M., A RP, D., YAMAGUCHI ,                 code clones by building ast-based markov chains model. In
     F., R IECK , K., FAHL , S., AND ACAR , Y. Vccfinder: Finding                  Proceedings of the 37th IEEE/ACM International Conference
     potential vulnerabilities in open-source projects to assist code              on Automated Software Engineering (2022), pp. 1–13.
     audits. In Proceedings of the 2015 ACM SIGSAC Conference                 [56] X IAO , Y., C HEN , B., Y U , C., X U , Z., Y UAN , Z., L I , F., L IU ,
     on Computer and Communications Security (2015), pp. 426–                      B., L IU , Y., H UO , W., Z OU , W., AND S HI , W. Mvp: Detect-
     437.                                                                          ing vulnerabilities using patch-enhanced vulnerability signa-
[42] R AWAT, S., JAIN , V., K UMAR , A., C OJOCAR , L., G IUFFRIDA ,               tures. In Proceedings of the 29th USENIX Security Symposium
     C., AND B OS , H. Vuzzer: Application-aware evolutionary                      (2020), pp. 1165–1182.
     fuzzing. In Proceedings of the 2017 Annual Network and                   [57] X U , Z., Z HANG , Y., Z HENG , L., X IA , L., BAO , C., WANG ,
     Distributed System Security Symposium (2017), pp. 1–14.                       Z., AND L IU , Y. Automatic hot patch generation for android
[43] S AJNANI , H., S AINI , V., S VAJLENKO , J., ROY, C. K., AND                  kernels. In Proceedings of the 29th USENIX Security Sympo-
     L OPES , C. V. Sourcerercc: Scaling code clone detection to                   sium (2020), pp. 2397–2414.
     big-code. In Proceedings of the IEEE/ACM 38th International              [58] YAMAGUCHI , F., G OLDE , N., A RP, D., AND R IECK , K. Mod-
     Conference on Software Engineering (2016), pp. 1157–1168.                     eling and discovering vulnerabilities with code property graphs.
[44] S TEPHENS , N., G ROSEN , J., S ALLS , C., D UTCHER , A.,                     In Proceedings of the 2014 IEEE Symposium on Security and
     WANG , R., C ORBETTA , J., S HOSHITAISHVILI , Y., K RUEGEL ,                  Privacy (2014), pp. 590–604.
     C., AND V IGNA , G. Driller: Augmenting fuzzing through se-              [59] Z HANG , J., WANG , X., Z HANG , H., S UN , H., WANG , K.,
     lective symbolic execution. In Proceedings of the 2016 Annual                 AND L IU , X. A novel neural source code representation based
     Network and Distributed System Security Symposium (2016),                     on abstract syntax tree. In Proceedings of the IEEE/ACM
     pp. 1–16.                                                                     41st International Conference on Software Engineering (2019),
[45] VANEGUE , J., AND L AHIRI , S. K. Towards practical reactive                  pp. 783–794.
     security audit using extended static checkers. In Proceedings            [60] Z HAO , J., X IA , K., F U , Y., AND C UI , B. An ast-based code
     of the 2013 IEEE Symposium on Security and Privacy (2013),                    plagiarism detection algorithm. In Proceedings of the 10th In-
     pp. 33–47.                                                                    ternational Conference on Broadband and Wireless Computing,
[46] V IEGA , J., B LOCH , J., KOHNO , Y., AND M C G RAW, G. Its4:                 Communication and Applications (2015), pp. 178–182.
     A static vulnerability scanner for c and c++ code. In Pro-
     ceedings of the 16th Annual Computer Security Applications




1882     33rd USENIX Security Symposium                                                                                         USENIX Association
A     Simple Vulnerability Features                                        The third group comprises 42 operators, which are often
Given the syntactic features of vulnerabilities, we extracted           directly related to the built-in semantics of programming
177 features belonging to the following four groups from each           languages. These operators can map directly to underlying
code snippet as shown in Table 4.                                       computer instructions or the semantic rules of high-level lan-
   The first group comprises 42 sensitive APIs, which are re-           guages without requiring additional function calls. Addition-
lated to memory management, string operations, locks and                ally, the use of operators may pose potential risks, such as
concurrency, and system-level functionalities. Improper use             integer overflow and bitwise operation errors. Therefore, our
of these APIs for memory allocation, release, and manipu-               crucial features include operators.
lation may lead to issues such as memory leaks and buffer                  The fourth group comprises 73 C/C++ keywords. In C/C++,
overflows. Using unsafe string manipulation functions may               keywords are identifiers with special meanings, holding sig-
result in vulnerabilities like buffer overflows and format string       nificant positions in the syntax of programming languages.
vulnerabilities. Incorrect use of locks can lead to concurrency         Compilers use keywords to represent the fundamental struc-
issues like deadlocks and race conditions. Inappropriate use            tures, control flow, data types, and other fundamental elements
of system-level operations may result in problems such as per-          of the code. Thus, our crucial features include keywords.
mission issues, data inconsistency, and denial-of-service at-           B    Target Software
tacks. Hence, our crucial features include APIs that are prone          The target systems are presented in Table 5.
to unsafe behavior in the C/C++ programming languages.
   The second group comprises 20 format strings, which are                                 Table 5: Target software
critical features in vulnerabilities. Improper input validation          IDX Name           Version #Lines          Domain
or incorrect use of format strings when using format string              T1 FreeBSD         12.2.0 15,573,896 Operating System
functions (e.g., “printf ”, “sprintf ”, “fprintf ”, etc.) often leads    T2 SeaMonkey       2.53.18 8,370,870  Internet App Suite
to potential security vulnerabilities, such as code injection            T3 Turicreate      6.4.1 5,003,684    Machine Learning
attacks. Therefore, our crucial features include format strings.         T4 MongoDB         r4.2.11 3,295,598       Database
                                                                         T5     Xemu        0.7.118 1,642,871       Emulator
                                                                         T6     PHP         8.3.2 1,390,193    Scripting Language
             Table 4: Simple Vulnerability Features                      T7 OpenCV          4.5.1 1,201,122     Computer Vision
                   alloc, free, mem, copy, new, open, close,             T8    FFmpeg       n4.3.2 1,118,186 Multimedia Processing
                 delete, create, release, sizeof, remove, clear,         T9      Xen        4.17.3 527,124        Virtualization
                     dequene, enquene, detach, Attach, str,              T10 OpenMVG         2.1    490,103     Image Processing
    sensitive                                                            Total    -            -    38,613,647          -
                     string, lock, mutex, spin, init, register,
      APIs
                 disable, enable, put, get, up, down, inc, dec,
                     add, sub, set, map, stop, start, prepare,
                            suspend, resume, connect
                                                                        C    Evaluation Environment
                                                                        We employ the precise and efficient open-source function
                   %d, %i, %o, %u, %x, %X, %f, %F, %e,
     format                                                             parser Ctags [4] to extract functions from vulnerability files,
                  %E, %g, %G, %a, %A, %c, %C, %s, %S,
     strings                                                            patch files, and the target software. We use Tree-Sitter [3]
                                     %p, %n
                                                                        to extract the AST of functions and Joern [58] to generate
                   bitand, bitor, xor, not, not_eq, or, or_eq,
                                                                        taint paths for functions. FIRE is implemented using 2,836
                  and, ++, –, +, -, *, /, %, =, +=, -=, *=, /=,
    operators                                                           lines of Python code. The experiments are conducted on a
                %=, «=, »=, &=, =,   ˆ |=, &&, ||, !, ==, !=, >=,
                                                                        machine with a 3.40 GHz Intel i7-13700k processor and 48
                            <=, >, <, &, |, «, », , ,̂ ->
                                                                        GB of RAM, running on ArchLinux with Linux Zen Kernel.
                    asm, auto, alignas, alignof, bool, break,
                                                                        The memory usage of FIRE is 20 GB. All the advanced
                 case, catch, char, char16_t, char32_t, class,
                                                                        methods compared in the experiments are configured with
                    const, const_cast, constexpr, continue,
                                                                        settings identical to those reported in their respective original
                 decltype, default, do, double, dynamic_cast,
                                                                        papers.
                  else, enum, explicit, export, extern, false,
     C/C++
                  float, for, friend, goto, if, inline, int, long,      D    False Positive and False Negative Analysis
                    mutable, namespace, noexcept, nullptr,                   for VUDDY and MOVERY
       key-
                       operator, private, protected, public,            FP Analysis for VUDDY and MOVERY. In addition to false
     words
                 reinterpret_cast, return, short, signed, static,       positives caused by exceeding function granularity, VUDDY
                    static_assert, static_cast, struct, switch,         generates significant false positives mainly due to abstrac-
                 template, this, thread_local, throw, true, try,        tion. VUDDY detects renaming clones of vulnerability by
                 typedef, typeid, typename, union, unsigned,            replacing all formal parameters, local variables, data types,
                     using, virtual, void, volatile, wchar_t,           and function calls with specific symbols in a function. How-
                      while, compl, override, final, assert             ever, when a vulnerability is fixed by only changing these



USENIX Association                                                                         33rd USENIX Security Symposium          1883
abstracted parts, the abstracted vulnerable function and the         F         Multi-Version Vulnerability
patched function will have identical hash values. As a re-           We use FIRE to investigate different versions of OpenMVG
sult, VUDDY may incorrectly identify patched functions as            (i.e., versions 0.1, 0.5, 0.7, 0.8, 1.0, 1.6, 2.0, and the latest
vulnerabilities, leading to a large amount of false positives.       version 2.1) to analyze vulnerability propagation between
Moreover, excessive abstraction can also cause hash collisions       versions. We find that there is a vulnerability that propagates
for relatively simple functions. For example, the patch in List      continuously from version 0.1 to version 2.1. Version 0.8
5 fixes a vulnerability by adding range checks for block device      introduced a large number of vulnerabilities, of which only
read or write requests. However, due to excessive abstraction,       one was fixed in version 1.0, and the remaining 38 vulnera-
the target function in List 6 shares the same hash value as the      bilities propagated continuously to version 2.1, where a new
vulnerable function in List 5, even though they implement            vulnerability was introduced. This phenomenon illustrates
entirely different functionalities and the target function is not    that vulnerability propagation between different versions of
vulnerable, leading to false positives.                              the same software is serious. Vulnerabilities introduced by
   Similar to the second false positive reason in our method,        a certain version will have a higher probability of propagat-
MOVERY generated a large number of false positives due               ing to subsequent versions, which is more serious than the
to the similarity of vulnerabilities. As the absence of restric-     propagation between different software. Therefore, efficient
tions limits the target function to only match the most similar      vulnerability detection is needed to detect vulnerabilities on
vulnerability within the same CVE, MOVERY generates sig-             time and prevent further propagation.
nificantly more false positives for this reason compared to          1          nl1e = l1e_from_intpte ( val ) ;
FIRE. Additionally, similar to VUDDY, MOVERY also ex-                2    +     if ( !( l1e_get_flags (nl1e) & _PAGE_PRESENT) &&
hibits false positives caused by abstraction.                                    pv_l1tf_check_l1e(d, nl1e) )
                                                                     3    +          return X86EMUL_RETRY;
1  BlockDriverAIOCB *bdrv_aio_readv(BlockDriverState *bs,            4          switch ( ret = get_page_from_l1e(nl1e , d, d) )
        int64_t sector_num, QEMUIOVector *iov, int nb_sectors ,      5          {
       BlockDriverCompletionFunc *cb, void *opaque) {                6               default :
2 +    if (bdrv_check_request(bs , sector_num, nb_sectors ) )
3 +         return NULL;                                                          List 7: A patch snippet for CVE-2018-3620
4 +
5      return bdrv_aio_rw_vector(bs , sector_num, iov , nb_sectors   1          nl1e = l1e_from_intpte ( val ) ;
        , cb, opaque, 0) ;                                           2 *        if ( !( l1e_get_flags (nl1e) & _PAGE_PRESENT) )
6  }                                                                 3 *        {
                                                                     4 *             if ( pv_l1tf_check_l1e (d, nl1e) )
          List 5: A patch snippet for CVE-2008-0928                  5 *                  return X86EMUL_RETRY;
                                                                     6 *        }
                                                                     7          else
                                                                     8          {
1   int xmlParseBalancedChunkMemory(xmlDocPtr doc,
                                                                     9               switch ( ret = get_page_from_l1e(nl1e , d, d) )
        xmlSAXHandlerPtr sax, void *user_data, int depth , const
                                                                     10              {
        xmlChar * string , xmlNodePtr * lst ) {
                                                                     11                   default :
2        return xmlParseBalancedChunkMemoryRecover(doc, sax,
        user_data, depth, string , lst ,0) ;                                  List 8: A snippet for Function ptwr_emulated_update
3   }

      List 6: Function xmlParseBalancedChunkMemory                   1 +        if ( buf−>have_grant )
                                                                     2 +        {
                                                                     3 +              __release_grant_for_copy (buf−>domain, buf−>ptr.u. ref ,
   FN Analysis for VUDDY and MOVERY. The false neg-                                buf−>read_only);
atives in VUDDY arise from its use of exact matching. If             4    +           buf−>have_grant = 0;
                                                                     5    +     }
a target function undergoes changes that do not affect the
                                                                     6          if ( buf−>have_type )
triggering of the vulnerability, VUDDY cannot detect such            7          {
vulnerabilities. In other words, VUDDY can only detect exact         8                put_page_type(buf−>page);
clones and renamed clones of vulnerability. As for MOVERY,           9          .....
                                                                     10               put_page(buf−>page);
since it also uses the same deletion and addition line detection     11               buf−>page = NULL;
as ours, the reasons for its false negatives are similar to ours.    12         }
Moreover, MOVERY does not count the occurrences of added             13 −       if ( buf−>have_grant )
lines, leading to more false negatives than FIRE.                    14 −       {
                                                                     15 −             __release_grant_for_copy (buf−>domain, buf−>ptr.u. ref ,
                                                                                   buf−>read_only);
E     Code Snippets                                                  16   −           buf−>have_grant = 0;
List 7, List 8, and List 9 are the code snippets used in Section     17   −     }
5.6.
                                                                                  List 9: A patch snippet for CVE-2017-15597




1884     33rd USENIX Security Symposium                                                                                 USENIX Association
