V1scan: Discovering 1-day Vulnerabilities in Reused
 C/C++ Open-source Software Components Using
          Code Classification Techniques
 Seunghoon Woo, Eunjin Choi, Heejo Lee, and Hakjoo Oh, Korea University
       https://www.usenix.org/conference/usenixsecurity23/presentation/woo




      This paper is included in the Proceedings of the
            32nd USENIX Security Symposium.
                   August 9–11, 2023 • Anaheim, CA, USA
                                978-1-939133-37-3




                                       Open access to the Proceedings of the
                                        32nd USENIX Security Symposium
                                             is sponsored by USENIX.
       V1 SCAN: Discovering 1-day Vulnerabilities in Reused C/C++ Open-source
             Software Components Using Code Classification Techniques

                                     Seunghoon Woo, Eunjin Choi, Heejo Lee∗ , Hakjoo Oh
                                  Korea University, {seunghoonwoo, silver_jin, heejo, hakjoo_oh}@korea.ac.kr




                              Abstract                                      However, improper OSS reuse may compromise the secu-
We present V1 SCAN, an effective approach for discovering                rity of the entire system (e.g., vulnerability propagation [9,
1-day vulnerabilities in reused C/C++ open-source software               14, 15, 34]). To obviate the threats imposed by unmanaged
(OSS) components. Reusing third-party OSS has many bene-                 OSS reuse, many approaches have been proposed for detect-
fits, but can put the entire software at risk owing to the vul-          ing vulnerabilities in OSS components. These approaches are
nerabilities they propagate. In mitigation, several techniques           mainly classified into version- and code-based techniques.
for detecting propagated vulnerabilities, which can be clas-                • A version-based approach discovers vulnerabilities by
sified into version- and code-based approaches, have been                      identifying OSS versions [9, 36, 40]. It determines
proposed. However, state-of-the-art techniques unfortunately                   whether the versions contain known vulnerabilities such
produce many false positives or negatives when OSS projects                    as Common Vulnerabilities and Exposures (CVE).
are reused with code modifications.                                         • A code-based approach detects propagated vulnerabili-
   In this paper, we show that these limitations can be ad-                    ties by identifying codes that are syntactically or seman-
dressed by improving version- and code-based approaches                        tically similar to vulnerable code [12, 14, 34, 37].
and synergistically combining them. By classifying reused                    Although resolving vulnerabilities is crucial for securing
code from OSS components, V1 SCAN only considers vulner-                  software, existing version- and code-based approaches easily
abilities contained in the target program and filters out unused          produce false positives or negatives, resulting in impeding an
vulnerable code, thereby reducing false alarms produced by                effective vulnerability management process. This is primarily
version-based approaches. V1 SCAN improves the coverage                   owing to the recent tendency of developers to typically reuse
of code-based approaches by classifying vulnerable code and               OSS with code or structural modifications [9, 36].
then detecting vulnerabilities propagated with code changes in
various code locations. Evaluation on GitHub popular C/C++                Limitations of existing approaches. Existing version-based
software showed that V1 SCAN outperformed state-of-the-art                approaches (e.g., [9, 36, 40]) easily produce false positives be-
vulnerability detection approaches by discovering 50% more                cause they fail to consider the impact of modified OSS reuse
vulnerabilities than they detected. In addition, V1 SCAN re-              on vulnerability propagation, and thus misinterpret the unused
duced the false positive rate of the simple integration of ex-            vulnerable code as still being present in the target program. In
isting version- and code-based approaches from 71% to 4%                  contrast, existing code-based approaches (e.g., [12,14,34,37])
and the false negative rate from 33% to 7%. With V1 SCAN,                 easily report false negatives when the syntax of the vulner-
developers can detect propagated vulnerabilities with high                able code is modified. Moreover, because these approaches
accuracy, maintaining a secure software supply chain.                     focus on a specific granularity (e.g., function units), they miss
                                                                          vulnerabilities that exist outside the selected granularity.
                                                                          Our approach. To overcome their shortcomings, we present
1    Introduction                                                         V1 SCAN, a novel approach for the precise and comprehensive
                                                                          discovery of 1-day security vulnerabilities propagated as a
Open-source software (OSS) reuse has become an indispens-
                                                                          result of the reuse of C/C++ OSS components.
able trend in software development [9, 36, 41]. In addition to
                                                                             We devise a new way to combine version- and code-based
the benefits of using existing functionalities, reusing OSS in-
                                                                          approaches to take full advantage of their strengths and avoid
creases the reliability of software because OSS is often more
                                                                          weaknesses. The main idea of V1 SCAN, which is significantly
exposed to verification by multiple parties.
                                                                          distinguishable from existing approaches, is to detect propa-
    * Heejo Lee is the corresponding author.                              gated vulnerabilities using the code classification techniques.



USENIX Association                                                                          32nd USENIX Security Symposium           6541
   Given a target program, V1 SCAN first detects vulnerabili-       2     Terminology and motivation
ties based on the identified OSS versions. To focus only on
reused vulnerabilities, V1 SCAN uses a reused code classifica-      2.1     Basic terminology
tion technique that divides reused OSS functions into three
groups: exactly reused, changed, and unused. By filter-             We first clarify the following terms used throughout the paper.
ing out unused and repaired vulnerable functions, V1 SCAN               • OSS reuse. This refers to the process of utilizing all or
reduces false alarms of the existing version-based approaches.            some of the OSS functions (e.g., copying and pasting of
   V1 SCAN complements vulnerability detection results us-                functions from third-party OSS projects) [9, 36].
ing a code-based approach. To expand vulnerability detec-               • OSS component. This refers to an entire OSS project or
tion coverage, V1 SCAN first clarifies vulnerability locations            sometimes a portion of an OSS codebase that is reused
(function, structure, macro, or variable) using a vul-                    in a target program [36].
nerable code classification technique, and then detects propa-          • OSS version. We define that an OSS version follows
gated vulnerabilities for each location. Here, V1 SCAN only               the three-component semantic versioning notation with
considers the core lines directly related to the vulnerability to         major.minor.patch by default [7].
counter code changes caused by modified OSS reuse, thereby
                                                                        • 1-day (or N-day) vulnerability. This refers to a vul-
addressing false negatives of existing code-based approaches.
                                                                          nerability that is known to responsible developers and
   Finally, V1 SCAN confirms the propagated vulnerabilities
                                                                          for which a corresponding security patch has been re-
in the target program by consolidating the results of the im-
                                                                          leased [9, 38]. These vulnerabilities can propagate to
proved version- and code-based approaches.
                                                                          other software due to OSS reuse, compromising the se-
Evaluation. For the experiment, we collected 4,612 CVE                    curity of the entire system.
patches from the National Vulnerability Database (NVD) [22]
and gathered Common Platform Enumeration (CPE) [21] on
137,892 CVE vulnerabilities. We evaluated V1 SCAN using             2.2     Code classification
popular C/C++ software on GitHub.                                   For precise vulnerability detection, we leverage the classifi-
   When we applied the V1 SCAN, M OVERY [34], and                   cation of reused and vulnerable code. This is because false
V0Finder [35] to the selected ten target programs, V1 SCAN          positives and negatives may occur in vulnerability discovery
detected 50% more vulnerabilities (137 vulnerabilities) than        if various types of reused and vulnerable code are not properly
the existing approaches, achieving a precision of 96% and           classified and considered (see Section 2.3). Figure 1 depicts
a recall of 91% (see Section 5.1). It is remarkable that            the code classification defined in this paper.
V1 SCAN could reduce the false negative rate of M OVERY and
V0Finder from 40% and 55% to 9%. Furthermore, V1 SCAN               Reused code classification. When developers reuse an OSS
could discover more propagated vulnerabilities than the com-        project, they often modify the code of the original OSS
bined results of existing version- [14] and code-based [36]         project [9, 36]. We classified the types of OSS codes that
approaches, while reducing the false positive rate from 71%         were reused into the following three categories, according to
to 4% and the false negative rate from 33% to 7% (see Section       the extent of modification of the code.
5.2). Moreover, when we applied V1 SCAN to 4,434 popular                • Exactly reused (E): OSS code (e.g., functions or files)
C/C++ software (ranging from 1K to 20M lines of code),                    is reused without any code changes.
V1 SCAN could detect vulnerabilities within 20 seconds for              • Changed (C): OSS code is reused with code changes.
each software (excluding preprocessing time), indicating that           • Unused (U): OSS code is not reused (not included in
V1 SCAN is sufficiently fast for practical use (see Section 5.3).         the codebase of the target program).
Contributions. We summarize our contributions below.                Vulnerable code classification. Security vulnerabilities can
  • We propose V1 SCAN, a new approach for precisely de-            exist in various locations in the source code. Specifically, we
    tecting 1-day vulnerabilities in a target program. The          consider the following four code locations.
    key technical contribution is the effective integration of
                                                                        • Function (F). e.g., void main (...) {...}
    version- and code-based approaches by leveraging the
    classification of reused and vulnerable code.                       • Structure (S). e.g., struct oss {...};
  • We examined the manner in which modified OSS reuse                  • Macro (M). e.g., #define ...
    affects the vulnerability discovery process, and propose            • Variable (V). e.g., const int ...;
    an effective solution for detecting vulnerabilities in mod-        When we examined 4,612 C/C++ security patches, code
    ified C/C++ OSS components.                                     patches applied to the selected four code locations accounted
  • V1 SCAN discovered 137 vulnerabilities in ten target            for over 97% (see Section 4.3). Therefore, we determined
    programs with 96% precision and 91% recall, thereby             that considering these four code locations could cover C/C++
    outperforming existing approaches.                              security patches comprehensively.



6542    32nd USENIX Security Symposium                                                                       USENIX Association
                                                         Vulnerable source file        Table 1: Vulnerability detection results for ReactOS using the
 Target program
                                                           Function   Structure
                                                                                       V1 SCAN, version-based, and code-based approaches. We mea-
                        OSS codebase                         (F)         (S)
              Reused
                                                                                       sured FNs by considering all TPs discovered in the three ap-
                       Exact (E)     Unused (U)
                                                                                       proaches as the ground truth.
                                                            Macro     Variable
                                                             (M)        (V)
                            Changed (C)
                                                                                                  Approach                #TP∗ #FP† #FN‡ Precision R§
      (a) Reused code classification              (b) Vulnerable code classification     Version-based approach (V )         5     47     22      10%      19%
            Figure 1: Depiction of the code classification.                                Version-based approach
                                                                                                                            20     29      7      41%      74%
                                                                                        (manually correcting versions)
                                                                                          Code-based approach (C)           13      8     14      62%      48%
2.3      Problem statement                                                                Union of the version- and
                                                                                                                            15     55     12      21%      56%
In this paper, we focus on the problem in which existing                                code-base approaches (V ∪C)
version- and code-based approaches fail to precisely detect                                       V1 SCAN                   26      1      1      96%      96%
1-day vulnerabilities in target software, leaving threats un-                           #TP∗ : #True positives, #FP† : #False positives, #FN‡ : #False negatives,
mitigated and making the vulnerability management process                                             R§ : TP detection rate (#TP / (#TP + #FN)).
ineffective. Two main issues with the existing version- and
                                                                                       Version-based approach. We used C ENTRIS [36], a recent
code-based approaches are summarized as follows.
                                                                                       approach for precisely identifying modified OSS components.
  • Version-based approaches produce many false positives                              C ENTRIS identified 23 C/C++ OSS components and versions
    because they do not consider the modification of reused                            thereof in ReactOS. Subsequently, we investigated the CVE
    vulnerable code.                                                                   vulnerabilities contained in the components using the CPE
  • Code-based approaches report many false negatives be-                              of NVD [21], which specifies the software affected by each
    cause they do not consider code locations in which vul-                            CVE (details are introduced in Section 3.3).
    nerabilities exist.                                                                   Consequently, 10 components, including LibTIFF and
                                                                                       MbedTLS, were identified as vulnerable, with 52 CVE vul-
   First, although 57% of the C/C++ OSS codebase is changed
                                                                                       nerabilities. However, when we manually examined these 52
or excluded from OSS reuse in practice [36], existing version-
                                                                                       CVEs, we observed that the version-based approach produced
based approaches (e.g., [9, 36, 40]) fail to consider the impact
                                                                                       many false positives: 47 CVEs (90%) were false positives,
of modified reuse on vulnerability propagation. Even if the
                                                                                       whereas only five CVEs were identified correctly. Most false
vulnerable code is excluded during OSS reuse, or is repaired
                                                                                       positives were the result of incorrect predictions of the com-
by backporting the security patch, existing version-based ap-
                                                                                       ponent version (see Section 2.3).
proaches fail to filter out this and produce false alarms.
                                                                                          Despite our attempt to rectify the problem by manually cor-
   Moreover, version-based approaches can produce false re-
                                                                                       recting the component versions, the version-based approach
sults when component versions are misidentified. Because
                                                                                       still produced 29 false positives. This is because the version-
OSS codes often undergo modifications during the reuse pro-
                                                                                       based approach misinterprets that the target program still
cess, it is challenging to map one version to the entire code-
                                                                                       contains unused vulnerable code or vulnerable code repaired
base of the reused component (e.g., code from multiple OSS
                                                                                       by backporting security patches. For example, the ReactOS
versions can be mixed) [36]. Leveraging a Software Bill of
                                                                                       team resolved three CVE vulnerabilities contained in Libtirpc
Materials (SBoM) [29] also presents challenges, as the cur-
                                                                                       v0.1.11 by backporting the security patches, instead of up-
rent SBoM for C/C++ mostly lacks consideration for modified
                                                                                       dating the entire Libtirpc to a safe version. However, the
reuse; it maps a single version to an OSS component and can
                                                                                       version-based approach failed to filter out the resolved vul-
thus produce false results in vulnerability discovery.
                                                                                       nerabilities, misconfirming that the three CVEs were still
   On the other hand, existing code-based approaches (e.g.,
                                                                                       included in ReactOS (i.e., producing false positives).
[12, 14, 34, 37]) report many false negatives because they
mainly focus on detecting propagated vulnerabilities within a                          Code-based approach. We used VUDDY [14], a function-
specific granularity (e.g., function units). Furthermore, they                         based vulnerable code detection approach that was specifi-
do not precisely identify propagated vulnerable code with                              cally developed for the discovery of 1-day vulnerabilities. We
various syntaxes (e.g., propagated with code changes).                                 tested VUDDY using 4,612 CVE patches (see Section 4.3)
                                                                                       in abstraction mode, which makes VUDDY robust to changes
                                                                                       in parameters, local variables, and called function names.
2.4      Motivating example
                                                                                          When we applied VUDDY to ReactOS, we confirmed that
We attempted to discover 1-day vulnerabilities in ReactOS                              VUDDY reported many false negatives, which we attributed
v0.4.13, which is a free Windows-compatible operating sys-                             to the syntax diversity of the vulnerable code. VUDDY could
tem. We used V1 SCAN, version-based, and code-based ap-                                discover only 13 (48%) of 27 vulnerabilities and failed to de-
proaches and then examined each vulnerability detection re-                            tect 14 vulnerable functions. Our measurement of the Jaccard
sult. Table 1 summarizes the vulnerability detection results.                          similarity [32] (considering a function as a set of lines) be-



USENIX Association                                                                                          32nd USENIX Security Symposium                  6543
                                                                                 P1. Classification                P2.Detection            P3. Consolidation
tween the disclosed vulnerable functions and the vulnerable
                                                                                 Improved version-based approach
functions that existed in ReactOS, indicated a similarity of                        Reused code           Vulnerability       Filtering
                                                                     INPUT          classification         detection        false alarms        OUTPUT
less than 60% in the six cases. Moreover, because VUDDY               Target                                                                       1-day
is not designed to detect vulnerabilities that exist outside func-   program     Improved code-based approach                                  vulnerabilities
                                                                                  Vulnerable code         Vulnerability
tions, it missed two vulnerabilities.                                              classification          detection

   Finally, VUDDY produced eight false positives, all of
                                                                                  Figure 2: High-level overview of V1 SCAN.
which were caused by abstraction. In the case of a security
patch that changes only its abstraction targets, VUDDY can-
not distinguish between vulnerable and patched functions,            Design assumption and text preprocessing. We designed
thereby producing false positives.                                   V1 SCAN to detect vulnerabilities at the source code level. Al-
                                                                     though V1 SCAN can operate with any granularity unit, we fo-
V1 SCAN. V1 SCAN discovered 26 vulnerabilities in ReactOS
                                                                     cus on the function units in the version-based approach, which
while eliminating most false positives and negatives produced
                                                                     are suitable for identifying reused OSS components [36].
by the existing approaches. It is noteworthy that V1 SCAN
                                                                        Subsequently, V1 SCAN extracts (1) all functions from ev-
detected more vulnerabilities with significantly fewer false
                                                                     ery version of the OSS in our dataset (see Section 4.2), and
positives than the union results of existing approaches.
                                                                     (2) all functions of the target program, using a function parser
   Here we introduce the LibTIFF v4.0.10 case, which is
                                                                     (see Section 4.1). V1 SCAN then performs text preprocessing
reused in ReactOS. V1 SCAN could filter out vulnerabilities
                                                                     on all extracted functions to normalize the code; it removes
of LibTIFF that were not reused in ReactOS (e.g., CVE-2020-
                                                                     comments, linefeed, and whitespace from the function codes.
35521). In addition, V1 SCAN detected the CVE-2018-19210
                                                                        Moreover, V1 SCAN uses locality sensitive hashing (LSH),
vulnerability that was not discovered in the version-based
                                                                     which hashes similar input items into the same “buckets” with
approach, because the CPE provides an incorrect version
                                                                     high probability [33]; therefore, LSH can be utilized to ad-
(v4.0.9). Moreover, the CVE-2019-14973 vulnerability, in
                                                                     dress code modifications in a flexible manner.
which the security patch modified outside functions, was
                                                                        We applied LSH to all text-preprocessed functions in (1)
not detected by the code-based approach but discovered in
                                                                     the target program and (2) every version of OSS projects.
V1 SCAN. Note that the aforementioned vulnerabilities have
                                                                     Each LSH algorithm provides a functionality (Φ) to measure
been patched in the latest version of ReactOS.
                                                                     the distance between two inputs and the cutoff value (i.e.,
                                                                     threshold θ). Thus, the relationships in which the two func-
3     Design of V1 SCAN                                              tions ( f1 , f2 ) are identical, similar, or different can be defined
                                                                     as follows: let the output of Φ be an integer.
In this section, we describe the design of V1 SCAN, which can          • Identical: If Φ( f1 , f2 ) = 0, f1 and f2 are identical.
precisely detect propagated 1-day vulnerabilities.                     • Similar: If 0 < Φ( f1 , f2 ) ≤ θ, f1 and f2 are similar.
                                                                       • Different: If Φ( f1 , f2 ) > θ, f1 and f2 are different.
3.1    Overview
V1 SCAN synergistically combines version- and code-based             3.2       Classification phase (P1)
approaches to take advantage of their strengths and avoid            In this phase, V1 SCAN classifies reused OSS functions and
their weaknesses. The key idea of V1 SCAN, which is sig-             extracts code lines, which belong to the locations defined in
nificantly distinguishable from existing version- and code-          the vulnerable code classification, from the target program.
based approaches is that it classifies reused and vulnerable
codes. Such code classification techniques allow V1 SCAN to
                                                                     3.2.1     Improved version-based approach
eliminate false positives of version-based approaches while
addressing false negatives of code-based approaches.                 Component identification. The first step involved uncover-
   Figure 2 depicts the workflow of V1 SCAN, which com-              ing the OSS components in the target program, which, how-
prises three phases: classification (P1), detection                  ever, is difficult to precisely accomplish [9, 36]. Because the
(P2), and consolidation phase (P3). In P1, V1 SCAN clas-             identification of components is beyond the scope of this paper,
sifies the reused codes of OSS components and the vulnerable         we decided to use an existing, well-implemented component
code locations in the target program based on code classi-           identification tool. We took advantage of C ENTRIS [36] be-
fication (see Section 2.2). In P2, V1 SCAN detects vulnera-          cause it can precisely identify OSS components that have been
bilities contained in the target program by using improved           modified and its source code and dataset are publicly available.
version- and code-based approaches with code classification          Using C ENTRIS, we extracted the names of OSS components
techniques. Finally, in P3, V1 SCAN examines the two detec-          included in the target program. Note that C ENTRIS is only
tion results and consolidates them to confirm the propagated         concerned with component identification, and does not di-
vulnerabilities included in the target program.                      rectly participate in vulnerability detection.



6544    32nd USENIX Security Symposium                                                                                            USENIX Association
                                                                                                                           OSS name = {
Prevalent version identification. We then need to identify            Target program                      Target program    exactly reused : [ f1 , f2 , … ],
the version of each reused component. However, precise iden-                  OSS                                 OSS          changed     :{
                                                                                       OSS name,                                  version i : [ f3′, … ], …
tification of the version to which reused modified OSS com-                             version                                    none      : [ f5′, … ]},
                                                                                                                               unused      : [ f6 , … ]
ponents belong is challenging (see Section 2.3). Therefore,                                                                }
                                                                   (a) OSS identification in existing
V1 SCAN is designed such that it is not critically affected by        version-based approaches
                                                                                                         (b) Reused code classification in V1SCAN
the correctness of the identified versions.
                                                                                          fi : a function in the prevalent version
    Our approach is to first roughly detect vulnerabilities and                  fi′ : a function in the target program similar to fi .
then refine the results. In particular, we define the prevalent
version of the OSS component as the version to which the          Figure 3: Illustration of the differences between reused code
functions contained in the reused OSS codebase most closely       classification and OSS identification in existing approaches.
correspond. To identify the prevalent version, V1 SCAN first
compares all functions in the target program with those in        3.2.2    Improved code-based approach
every version of the OSS component. V1 SCAN extracts the
OSS functions that are exactly included in the target program,    Vulnerable code classification. To increase the vulnerability
and then verifies the versions to which each extracted function   detection scope, V1 SCAN classifies the code locations where
belongs. The most frequently identified version is designated     vulnerabilities exist, and then takes an effective vulnerability
the prevalent version of the OSS component.                       detection approach for each location. We considered the fol-
                                                                  lowing four code locations (see Section 2.2): 1 function, 2
Reused code classification. Next, V1 SCAN classifies func-        structure, 3 macro, and 4 (global and class) variable.
tions reused in OSS components based on the reused code
classification defined in Section 2.2. Because we consider        Code extraction. Subsequently, V1 SCAN extracts the code
the function unit in the version-based approach, V1 SCAN          lines belonging to the location in the target program. In fact,
classifies reused OSS functions based on code modifications.      extracting functions, structures, macros, and variables from
   When an OSS is reused in the target program, the functions     the target program can easily be performed using an exist-
in the original OSS can be in one of three states: (1) exactly    ing C/C++ parser (e.g., [5]). For more accurate vulnerability
reused, (2) changed, or (3) unused. Subsequently, V1 SCAN         detection, V1 SCAN further classifies the four locations into
examines the state of all the functions included in the preva-    two groups based on the syntactic similarity: (functions and
lent version of the OSS component. We consider the function       structures) and (macros and variables). Functions and struc-
relationships defined in Section 3.1.                             tures have in common that multiple code lines are enclosed in
                                                                  curly braces, while macros and variables generally consist of
  • Exactly reused functions. If a function in the prevalent      only one or two code lines. V1 SCAN extracts (1) LSH hash
    version is identical to a certain function in the target      values (see Section 3.1) and (2) source code lines from all
    program, it is considered reused in the target program.       functions and structures in every C/C++ source file in the tar-
  • Changed functions. If a function f ′ that exists in the       get program. We consider both hash values and lines of code
    target program is similar to function f in the prevalent      to reduce false positives in vulnerability discovery (details
    version, f is considered a changed function.                  are introduced in Section 3.3.2). For macros and variables,
                                                                  V1 SCAN extracts only the corresponding source code lines.
  • Unused functions. Among all functions in the prevalent
    version, those that did not belong to the exactly reused
                                                                  3.3     Detection phase (P2)
    or changed were included in the unused group.
                                                                  V1 SCAN detects propagated vulnerabilities in the target pro-
   The changed functions were further classified according
                                                                  gram, using improved version- and code-based approaches.
to the version to which they belonged. To this end, V1 SCAN
compares f ′ with all functions in every version of the OSS.
                                                                  3.3.1    Improved version-based approach
If f ′ belongs to any other version of the OSS and is not the
prevalent version, f ′ is stored in the group under the name of   Vulnerability detection. V1 SCAN detects vulnerabilities in
the associated version. In contrast, if f ′ does not belong to    the target program by using the prevalent version. We used
any version of the OSS, it is stored in the “none” group. OSS     CPE [21] to construct a CPE database that maps the CVEs
functions that do not belong to the prevalent version but are     to the affected OSS versions (see Section 4.3). By leveraging
contained in the target program, as detected in the prevalent     the CPE database, V1 SCAN identifies the CVE vulnerabilities
version identification, are also included in the changed group    included in the prevalent version of the OSS component. For
with their respective version names.                              example, the CPE of the Heartbleed vulnerability (CVE-2014-
   Figure 3 depicts the procedure to classify reused code com-    0160) specifies that the vulnerability exists in OpenSSL 1.0.1
pared with OSS identification in existing version-based ap-       to 1.0.1f. If OpenSSL is reused in the target program and
proaches. V1 SCAN stores the hash value of each function          its prevalent version is between 1.0.1 and 1.0.1f, V1 SCAN
obtained by applying the LSH algorithm (see Section 3.1).         determines that this vulnerability exists in the target program.



USENIX Association                                                                       32nd USENIX Security Symposium                             6545
Collection of vulnerable and patched functions. V1 SCAN                                       Table 2: Defined notations.
then removes false positives from the version-based vulner-
                                                                                     Notations             Description
ability detection results. To identify the resolved vulnerable
functions, we refer to the vulnerable and patched functions                              T       The target program.
of CVE vulnerabilities. To this end, we first collected the                              X       The vulnerability to be examined.
                                                                                         fv      The vulnerable function of X.
security patches for CVEs and then extracted the vulnerable
                                                                                         fp      The patched function of X.
and patched functions from these patches (see Section 4.3).
Thereafter, text preprocessing is applied to all vulnerable and
patched functions, after which the LSH algorithm is applied                     Here, a CVE vulnerability may (1) contain multiple vulner-
to generate hash values (see Section 3.1).                                  able functions or (2) not include any vulnerable functions. In
Filtering. Based on the classification of the reused code,                  the former case, the propagation of only one vulnerable func-
V1 SCAN checks for vulnerable functions and filters out false               tion may compromise the security of the entire system [12,14].
alarms from the vulnerability detection results. We consider                Therefore, if more than one vulnerable function remains af-
the four notations listed in Table 2.                                       ter filtering, V1 SCAN determines that CVE vulnerability has
                                                                            propagated to the target program. Conversely, in the latter
(1) Filtering unused vulnerable functions. The classifica-                  case, V1 SCAN determines CVE as the correct answer without
    tion of reused code simplifies the filtering of the unused              filtering. This may yield false positives; however, this rarely
    vulnerable functions. If fv is included in the “unused”                 occurs (i.e., not found in our dataset) and arises from our de-
    group (U), then V1 SCAN determines that fv is not reused                cision that a small number of false positives would be more
    in the target program.                                                  tolerable than missing vulnerabilities. Moreover, a security
                                                                            patch may alter the code beyond the scope of a function (e.g.,
                 ∀ fv | fv ∈ U → fv ∈
                                    / T ( fv is unused)                     a macro). In this case, we put it on hold and verify it at the
                                                                            code level (see Section 3.3.2).
(2) Filtering resolved vulnerable functions. If developers                      Finally, the vulnerability detection result of the version-
    resolve fv by backporting security patches, this function               based approach in which false positives are removed is ob-
    has the same (or similar) code syntax as that of f p be-                tained as the output of this phase.
    longing to the OSS versions that are safe from X. On
    this basis, if fv is not included in “exactly reused” but               3.3.2   Improved code-based approach
    has a similar function fv′ in the “changed” group (C),
    V1 SCAN determines that fv was either reused with code                  Vulnerability signature generation. V1 SCAN generates vul-
    changes (still vulnerable) or resolved by backporting se-               nerability signatures for each collected CVE and uses them
    curity patches. To extract only the latter cases, V1 SCAN               to detect propagated vulnerabilities. Vulnerability signatures
    checks the version to which fv′ belongs.                                are generated after identifying the location to which the code
                                                                            lines modified in the security patch belong to. For example,
    (2-1) If the version is not included in the CPE of X, it can            Listing 1 shows the patch snippet for CVE-2019-12904 in
          be determined that fv′ does not contain the vulnera-              Libgcrypt. The snippet contains a patch for all four types of
          bility. To determine this more thoroughly, V1 SCAN                code locations: macro (lines #3 and #4), variable (lines #6 and
          compares fv′ to both fv and f p . If the distance (Φ,             #7), structure (lines #9 and #10), and function (lines #14 and
          see Section 3.1) between fv and fv′ is greater than               #15). The locations of the code modified in the security patch
          the distance between f p and fv′ (i.e., more similar              are identified using an existing C/C++ parser (see Section 4).
          to f p than fv ), then V1 SCAN considers fv′ has been                Thereafter, V1 SCAN uses different indexing methods for
          resolved. This can be represented as follows; let v               each code location. Listing 2 presents the indexing results for
          be the version to which fv′ belongs.                              the patch code shown in Listing 1. All the code lines added
                                                                            and deleted in the security patch were stored. For functions
             ∀ fv′ ∈ C | v ∈
                           / CPE(X) ∧ Φ( f p , fv′ ) < Φ( fv , fv′ ) ≤ θ
                                                                       
                                                                            and structures, the LSH hash value is also stored, as described
                               → fv is resolved
                                                                            in Section 3.2.2. We consider hash values for reducing false
                                                                            alarms in vulnerability discovery. If we were to detect vulner-
    (2-2) If fv′ does not belong to any version of OSS, de-                 abilities by considering only the code lines added or deleted
          ciding whether fv′ is vulnerable based only on the                in a patch, numerous false alarms could occur, particularly
          similarity to the vulnerable function and patch func-             when short and general codes (e.g., else) are modified in
          tion may produce a false alarm. Therefore, we put                 the patch [14, 34]. Therefore, we attempted to resolve this
          it on hold and decide whether to filter this vulner-              issue using the hash value of the entire function or struc-
          ability through an improved code-based approach                   ture. V1 SCAN generates vulnerability signatures for all the
          of V1 SCAN (see Section 3.3.2).                                   collected CVE patches.



6546   32nd USENIX Security Symposium                                                                                USENIX Association
 Listing 1: A patch snippet for CVE-2019-12904 in Libgcrypt.           Listing 2: Example vulnerability signature for CVE-2019-12904.
1 //libgcrypt/cipher/cipher-gcm.c                                      1    MACRO
2 ...                                                                  2     + #ifdef HAVE_GCC_ATTRIBUTE_ALIGNED
3 + #ifdef   HAVE_GCC_ATTRIBUTE_ALIGNED                                3     + # define ATTR_ALIGNED_64 __attribute__ ((aligned (64)))
4+ #    define ATTR_ALIGNED_64 __attribute__ ((aligned (64)))          4
5 ...                                                                  5    VARIABLE
6 - static   const u16 gcmR[256] = {                                   6     - static const u16 gcmR[256] = {
 7 - 0x0000, 0x01c2, 0x0384, 0x0246, 0x0708, 0x06ca, 0x048c,           7     - 0x0000, 0x01c2, 0x0384, 0x0246, 0x0708, 0x06ca, 0x048c,
 8 ...                                                                 8
 9 + static struct {                                                   9    STRUCTURE (HASH: 3A5F116800...)
10 +   volatile u32 counter_head;                                      10    + static struct {
11 ...                                                                 11    + volatile u32 counter_head;
12 void prefetch_table(const void *tab, size_t len) {                  12
13 ...                                                                 13   FUNCTION (HASH: BBC0994B88...)
14 -    for (i = 0; i < len; i += 8 * 32)                              14    - for (i = 0; i < len; i += 8 * 32)
15 +    for (i = 0; len - i >= 8 * 32; i += 8 * 32)                    15    + for (i = 0; len - i >= 8 * 32; i += 8 * 32)


Function and structure vulnerability detection. V1 SCAN                   This method can distinguish between vulnerable and
then detects the vulnerabilities propagated to the target pro-         patched functions even when both deleted and added code
gram. To respond flexibly to code changes unrelated to a               lines exist in the target function. Therefore, V1 SCAN can de-
vulnerability, V1 SCAN focuses on the core code lines that             tect vulnerabilities with fewer false positives than existing
were added or deleted in the security patch [34, 37].                  simple code syntax checking approaches.
   The process of detecting vulnerabilities in functions and              V1 SCAN can detect exactly reused vulnerable functions
structures comprises two steps.                                        (structures) with the aid of hash comparison and identify vul-
S1. Hash comparison: First, V1 SCAN compares the hash                  nerable functions (structures) whose code syntax has been
    values of all functions (structures) in vulnerability sig-         changed using line comparison. This guarantees a higher
    natures with those of the target program. If a hash value          vulnerability detection rate than the existing code-based ap-
    that belongs to both the signature and target program is           proach that considers only hash comparison (e.g., [14]) and
    detected, V1 SCAN determines that the vulnerability has            lowers the false positive rate compared with the existing ap-
    been propagated to the target program. Otherwise, if a             proach that only considers line comparison (e.g., [12]).
    similar hash value is discovered, V1 SCAN moves to the             Macro and variable vulnerability detection. To detect
    next step, namely, line comparison.                                vulnerabilities in macros and variables (global and class
S2. Line comparison: When a similar function (structure)               variables), V1 SCAN compares the lines of code containing
    is detected between the vulnerability signature and the            macros and variables in vulnerability signatures to those in the
    target program, V1 SCAN checks whether code deleted                target program. If all the lines of code containing macros (vari-
    from (resp. added to) the patch was included (resp. was            ables) deleted (resp. added) by the patch were included (resp.
    not included) in the function (structure) of the target            not included) in the target program, V1 SCAN determines that
    program. If this is satisfied, V1 SCAN determines that             the target program contains the vulnerability.
    the target program contains the vulnerability.                        If the security patch did not add any lines of code, then only
                                                                       the deleted lines of code are used to check for vulnerability
   Here, if we only consider the code syntax in the line com-
                                                                       propagation. On the other hand, if the patch did not delete
parison, as with certain existing approaches (e.g., [35, 37]),
                                                                       any lines of code, it would be premature to conclude that the
false positives or negatives may arise especially when the code
                                                                       vulnerability was propagated by solely relying on the fact that
modified in the patch is short and general. Assume that the
                                                                       the lines of code added by the patch do not exist in the target
code line “else” is added by the patch. This code line may
                                                                       program. Thus, V1 SCAN omits the latter case to reduce false
exist in the vulnerable function. Hence, even if the vulnerable
                                                                       alarms. This could yield a small number of false negatives;
function is not patched, the function may be misinterpreted to
                                                                       however, this decision was made because the addition of lines
be safe because it contains the code line added by the patch.
                                                                       of code containing a macro or variables by a security patch
   Therefore, we decided to consider the number of times
                                                                       without removing any lines of code from all four vulnerable
deleted (added) code lines appear in the target function. Sup-
                                                                       code locations rarely occurs.
pose that a security patch deletes the code line ldel and adds
the code line ladd to the function fv . Let the function after            The vulnerability detection result of the improved code-
applying the patch be f p . V1 SCAN counts the number of               based approach in which false negatives are covered is ob-
times ldel and ladd appear in fv and f p , respectively. There-        tained as the output of this phase. Among the vulnerabilities
after, when a function fv′ similar to fv is detected through           held by the version-based approach (e.g., existing outside the
hash comparison, V1 SCAN counts the number of times ldel               function), the vulnerabilities detected in the code-based ap-
and ladd appear in fv′ . If the result is the same as that of fv but   proach are included in the detection result as correct answers,
differs from that of f p , fv′ is considered a vulnerable function.    and all others are considered false positives and filtered out.



USENIX Association                                                                          32nd USENIX Security Symposium           6547
3.4    Consolidation phase (P3)                                                       Table 3: CVE dataset overview.

By consolidating the vulnerability detection results of the                              Category                      Count (#)
improved version- and code-based approaches, V1 SCAN de-                • Security patches                               4,612
termines vulnerabilities that exist in the target program.                - Vulnerable and patched function pairs        7,675
    As explained in P1 and P2, V1 SCAN reduces false posi-                - Vulnerable and patched structure pairs        106
                                                                          - Vulnerable and patched macro pairs            221
tives and negatives in the version- and code-based approach.
                                                                          - Vulnerable and patched variable pairs         598
The false alarms produced by the version-based approach
                                                                        • CPE database
were removed through the reuse code classification-based                  - Contained CVEs                              137,892
filtering, and the false alarms of the code-based approach                - Collected vulnerable software               75,489
were prevented by using both the hash and line comparisons.               - Collected vulnerable versions               559,305
Moreover, V1 SCAN covers the false negatives of version- and
code-based approaches by combining their results. Vulnera-               Since the dataset of C ENTRIS was constructed in April
bilities included in less frequently identified versions (i.e., not   2020, we additionally collected versions generated after that
a prevalent version) can be covered by detecting them with            of each repository (as of April 2022). As a result, the number
the code-based approach of V1 SCAN. In addition, by leverag-          of versions increased from 229,326 to 246,512 in V1 SCAN.
ing vulnerable code classification and focusing only on core
vulnerable code lines, V1 SCAN can address false negatives
of existing code-based approaches. Therefore, we denote the           4.3    CVE dataset
union of the detection results of both approaches as the list of      For each CVE, V1 SCAN first collects the security patch, and
vulnerabilities contained in the target programs.                     then extracts necessary information (e.g., vulnerable func-
                                                                      tions) from the patch. V1 SCAN then constructs the CPE
4     Implementation of V1 SCAN                                       database, which is used in the improved version-based ap-
This section introduces the implementation of V1 SCAN, in-            proach. Table 3 summarizes the CVE dataset.
cluding its architecture and the datasets.                            Collecting security patches. We collected security patches
                                                                      of CVE vulnerabilities by leveraging existing approaches [11,
4.1    Architecture                                                   16, 35, 37]. We examined CVEs in the NVD and checked
                                                                      whether a “Git commit” URL was included in the references;
V1 SCAN comprises the two modules: a dataset collector and
                                                                      this URL provides the code-level security patches. Hence, we
a vulnerability detector. The dataset collector constructs the
                                                                      can obtain the security patch commits for CVE vulnerabilities
OSS and CVE datasets (see Section 4.2 and Section 4.3).
                                                                      by crawling the URLs. As a result, we collected 4,612 C/C++
   The vulnerability detector performs vulnerability discovery
                                                                      security patches from the NVD (as of August 2022).
on the target program, which is implemented in approximately
1,800 lines of Python code excluding external libraries. We           Identifying vulnerable locations. Because V1 SCAN uses
use C ENTRIS [36] to identify the OSS components in the               vulnerable code classification, it is necessary to identify the
target program. For the parser and LSH algorithm, we utilize          location to which the code modified by the security patch
Ctags [5] and TLSH [23, 30]. Ctags is a regular expression-           belongs. Each security patch provides (1) a Git index and (2)
based parser, and has the advantage of scalability and detec-         code line numbers that include vulnerable and patched code.
tion accuracy; it can be used to precisely parse C/C++ source            We access the index to obtain the vulnerable and patched
files without being affected by the code size of the target pro-      source files (e.g., using the “git show” command). We then
gram. In addition, because Ctags provides the functionality           parse the source files using Ctags [5]. Using this output, we
to identify functions, structures, macros, and variables from         can obtain the start and end line numbers of each function,
source files, it can be effectively used to classify vulnerable       structure, macro, and variable. Finally, we identify the loca-
locations. Next, we selected the TLSH [23, 30] as the LSH             tions that contain the modified code lines in the patch. If
algorithm, which is both accurate and scalable. We used the           the modified code lines belong to a function or structure, the
similarity measurement function provided by TLSH as it is,            entire code of the vulnerable and patched function (and struc-
and selected the cutoff value of 30 (see Section 3.1), which          ture) is extracted. If the modified code lines belong to a macro
was observed to be the most efficient in their paper [23].            or variable, the exact lines of code are extracted.
                                                                         As a result, we collected 7,675 vulnerable and patched
                                                                      function pairs, 106 structure pairs, 221 macro pairs, and 598
4.2    OSS dataset                                                    variable pairs. Over 97% of the code repaired by the patch was
The OSS dataset is utilized for identifying OSS components            included in one of the four locations. The remaining 3% were
in the target program. We leveraged the OSS dataset provided          code patches that very rarely appear, such as changing header
by C ENTRIS [36], which consists of all versions of the 10,241        file names. This confirms that considering these four locations
popular C/C++ OSS projects on GitHub.                                 for vulnerability detection is sufficiently comprehensive.



6548    32nd USENIX Security Symposium                                                                           USENIX Association
CPE database. To construct the CPE database, we extract                           Table 4: Target software overview.
CPEs of all CVEs registered in NVD using the NVD JSON               IDX    Name    Version #CVE† #OSS #C/C++ Line #Star§       Domain
feeds. We stored CPE in a dictionary, in which the vulnerable       S1 Turicreate v6.4.1      69    28     4,091,413 10.7K Machine learning
                                                                    S2 ReactOS v0.4.13        67    23     6,419,855 10.8K Operating system
software (with version) as the key and the CVEs contained in        S3 TizenRT 3.0_GBM        62    22     2,156,848 439 Operating system
the vulnerable software as the value; this dictionary becomes       S4 Aseprite v1.2.25       53    12       846,500 17K Animation tool
the CPE database. Consequently, we stored a total of 137,892        S5 FreeBSD v12.2.0        30    47    14,489,534 6.4K Operating system
                                                                    S6 MongoDB r4.2.11        28    13     2,822,534 21.5K    Database
CVEs with 75,489 vulnerable software information (a total of        S7 MAME        0228       24    26     4,541,014 5.8K     Emulator
559,305 versions) in the CPE database (as of August 2022).          S8 Filament   v1.9.9      16    16     1,295,918 13.8K Rendering engine
                                                                    S9    Godot   v3.2.2      16    21     1,298,228 48.1K Game engine
   The issue here is that the names and versions of the OSS         S10 ArangoDB v3.6.12      15    22     5,465,881 12.2K    Database
components detected in V1 SCAN follow the form provided            Total    -         -      380   230    43,427,725 147K         -
by GitHub (as with the C ENTRIS dataset), whereas CPE uses            †: #CVEs discovered by the version-based approach, §: #Stargazers.
its own form of vulnerable software and version names. For
example, Linux kernel v5.15 is referred as “torvalds/linux,
v5.15” on GitHub and “linux/linux_kernel, 5.15” on CPE. It         projects in descending order, we applied a version-based ap-
is nearly infeasible and time-consuming to check all the tens      proach to each software program, identified the number of
of thousands of vulnerable software lists and internal versions.   contained CVEs (with manual version correction), and se-
Therefore, we first examined the following software, and man-      lected the software that contained more than 10 CVEs (for the
ually match the software and version names of GitHub and           third criterion). Consequently, nine target software programs
those of CPE: (1) OSS that was reused in the target pro-           were selected. In addition, we included TizenRT1 , which con-
grams selected for the experiments (see Section 5.1) and (2)       tains many components and can represent industrial software.
frequently reused OSS projects mentioned in the C ENTRIS              Table 4 summarizes the ten selected target programs. The
paper (e.g., Zlib, Lua, and GoogleTest). Information on the        target programs that were selected based on the clear cri-
rest of the software will also be examined.                        teria had various codebase sizes ranging from 846,500 to
                                                                   14,489,534 C/C++ lines of code, and were obtained from di-
                                                                   verse domains (operating systems, emulators, and databases).
5   Evaluation                                                     Therefore, we determined that the selected target programs
In this section, we evaluate V1 SCAN based on the following        could provide generality to V1 SCAN during evaluation. Note
three questions.                                                   that we chose target programs with a considerable number
                                                                   of vulnerabilities for a more impartial accuracy assessment.
Q1. Detection accuracy: How precisely does V1 SCAN de-             V1 SCAN can detect vulnerabilities even in software with few
    tect vulnerabilities compared to the state-of-the-art vul-     vulnerabilities, without any limitations.
    nerability detection approaches? (Section 5.1)
Q2. Effectiveness: How effective is V1 SCAN compared to
    existing version- and code-based approaches in vulnera-
                                                                   5.1     Accuracy measurement
    bility discovery? (Section 5.2)                                Methodology. We compared V1 SCAN with the state-of-the-
Q3. Performance and scalability: How fast and scalable is          art vulnerability discovery approaches: M OVERY [34] and
    V1 SCAN in detecting vulnerabilities? (Section 5.3)            V0Finder [35], which are capable of discovering vulnerable
  We ran V1 SCAN on a machine with Windows 10, AMD                 codes propagated with code modifications to some extent. We
Ryzen 7 3700X @ 3.60 GHz, 48GB RAM, and 1TB SSD.                   used their default settings by referring to their paper.
                                                                      To evaluate accuracy, we used the following five metrics:
Target software selection. To demonstrate the generality of
                                                                   true positive (TP), false positive (FP), false negative (FN),
V1 SCAN, we selected target software based on the following
                                                                   precision (P = #TP/(#TP + #FP)), and TP detection rate (R =
three criteria: (1) popular C/C++ software, (2) containing a
                                                                   #TP/(#TP + #FN)). Because it is nearly infeasible to detect all
sufficient number of OSS components, and (3) including a
                                                                   vulnerabilities in a target program, we cannot easily measure
considerable number of CVE vulnerabilities.
                                                                   the FNs of the tested approaches. Therefore, we consider
    We examined GitHub [10], which is one of the most popu-
                                                                   only indisputable FNs; for example, FNs in V1 SCAN refer
lar hosting services, as the first criterion. We collected C/C++
                                                                   to the vulnerabilities detected by the other two approaches,
repositories that exhibited more than 5,000 stargazers (a pop-
                                                                   but were not discovered by V1 SCAN. The TPs and FPs were
ularity indicator) from GitHub and collected approximately
                                                                   determined by manual analysis, and two security analysts
600 software programs. As a sufficient number of CVEs were
                                                                   examined all vulnerability detection results. We examined
required for accuracy measurement, we selected the version
                                                                   the results by referring to (1) the detected vulnerable code,
of each software that was released last year (closest to January
                                                                   (2) the security patch, (3) the NVD description, and (4) issue
2021). For the second criterion, we ranked the 600 collected
                                                                   trackers that denote vulnerability.
software according to the number of OSS components iden-
                                                                     1 https://github.com/samsung/tizenrt
tified by C ENTRIS. While examining the ranked software



USENIX Association                                                                        32nd USENIX Security Symposium              6549
Table 5: Accuracy of V1 SCAN, M OVERY, and V0Finder in vulnerability detection. Results with the highest precision and TP detection
rate for each target program are highlighted in bold text.
    Target                              V1 SCAN                                         M OVERY                                     V0Finder
               CVEs∗
   program                #TP     #FP    #FN       P†      R‡      #TP     #FP            #FN      P          R     #TP     #FP       #FN    P              R
  Turicreate     36        32       1       4     0.97    0.89      22      5             14      0.81       0.61   22          2     14       0.92      0.61
   ReactOS       29        26       1       3     0.96    0.90      24      3              5      0.89       0.83   18          4     11       0.82      0.62
  FreeBSD        23        19       2       4     0.90    0.83      13      4             10      0.76       0.57   12          7     11       0.63      0.52
  MongoDB        14        14       0       0     1.00    1.00      4       0             10      1.00       0.29    4          0     10       1.00      0.29
   Filament      14        14       0       0     1.00    1.00      10      0              4      1.00       0.71    4          0     10       1.00      0.29
   TizenRT       10         9       0       1     1.00    0.90      4       1              6      0.80       0.40   3           1     7        0.75      0.30
   Aseprite       8         8       0       0     1.00    1.00      6       0              2      1.00       0.75    1          1      7       0.50      0.13
   MAME           8         7       2       1     0.78    0.88      6       1              2      0.86       0.75    2          1      6       0.67      0.25
    Godot         4        4        0       0     1.00    1.00      1       3              3      0.25       0.25   1           2     3        0.33      0.25
  ArangoDB        4        4        0       0     1.00    1.00      0       0              4      N/A        0.00   0           1     4        0.00      0.00
    Total        150       137      6      13     0.96    0.91      90     17             60      0.84       0.60   67       19       83       0.78      0.45
                 CVEs∗ : Total number of TPs detected by V1 SCAN, M OVERY, and V0Finder, P† : Precision, R‡ : TP detection rate.

                                                                                                                          V1SCAN      MOVERY          V0Finder
   Unlike V0Finder, which is compatible with our dataset,




                                                                            Count (#)
                                                                                        180
                                                                                                  137
M OVERY offers datasets with their own preprocessing ap-                                120             90                                             83
plied. Therefore, we additionally applied preprocessing to                                                   67                                 60
the vulnerability and patched functions we gathered (see Sec-                            60
                                                                                                                      6 17 19              13
tion 4.3), by referring to the M OVERY paper, e.g., extracting                            0
                                                                                                        TP                 FP                    FN
control dependency graphs of the vulnerable and patched
                                                                           Figure 4: Vulnerability detection results of V1 SCAN, M OVERY,
functions by using the Joern [39] parser.
                                                                           and V0Finder.
Overall results. Table 5 summarizes the vulnerability detec-
tion results. We confirmed that 150 CVE vulnerabilities were
                                                                           which neither the codes added nor deleted from the patch
discovered in ten target programs. Among them, 93 (62%)
                                                                           were present, was falsely detected as vulnerable.
vulnerabilities were reused in the target program with code
                                                                              In addition, when the code lines deleted in the patch exists
changes. Nevertheless, V1 SCAN showed substantially bet-
                                                                           in multiple locations in the vulnerable code, V0Finder mis-
ter accuracy than the other approaches. It is noteworthy that
                                                                           interpreted that the vulnerability still remains even after the
V1 SCAN could reduce the false negative rate of M OVERY and
                                                                           patch is applied, thereby generating false alarms.
V0Finder from 40% and 55% to 9%; V1 SCAN discovered
137 vulnerabilities from ten target programs, while existing               Accuracy of V1 SCAN. V1 SCAN significantly outperformed
approaches detected at most 90 vulnerabilities (see Figure 4).             the other approaches: V1 SCAN could considerably reduce
                                                                           FPs of M OVERY and V0Finder, while discovering more TPs.
FNs of existing approaches. In our experiments, M OVERY
                                                                           It is noteworthy that V1 SCAN showed high detection accu-
and V0Finder failed to detect many vulnerabilities, i.e., they
                                                                           racy regardless of the number of vulnerabilities discovered in
missed 60 and 83 vulnerabilities, respectively. We observed
                                                                           software; V1 SCAN succeeded in detecting propagated vulner-
that there are two main reasons for this: when the propagated
                                                                           abilities without false alarms even in Godot and ArangoDB, in
vulnerable code (1) underwent significant syntax change or
                                                                           which only a small number of vulnerabilities were discovered.
(2) existed outside of functions.
                                                                              Although V1 SCAN detected vulnerabilities precisely in
   M OVERY and V0Finder detect vulnerabilities by assum-
                                                                           most cases, it reported several false results (6 FPs and 13
ing that propagated vulnerable codes have similar syntax (e.g.,
                                                                           FNs). The six FPs were caused by similar code logic in the
over 50% similarity) to the disclosed vulnerable codes, caus-
                                                                           OSS components [1, 37]. If a function similar to one that was
ing failure in discovering vulnerable codes with significant
                                                                           repaired in the security patch existed in the target program,
syntax changes. Specifically, V0Finder reported more false
                                                                           V1 SCAN misinterpreted the reused function as being vulnera-
negatives compared to M OVERY as it was more limited in
                                                                           ble even though it was safe. Because the possibility of actual
detecting heavily modified vulnerable codes. Additionally,
                                                                           abuse was negligible, we determined these to be FPs.
they failed to detect seven vulnerabilities that exist outside of
                                                                              FNs in V1 SCAN were reported when the syntax of the
functions as they only consider function units.
                                                                           reused vulnerable function differed vastly from that disclosed
FPs of existing approaches. M OVERY and V0Finder pro-                      by the NVD (e.g., syntax similarity of less than 15%). Addi-
duced 17 and 19 false positives in vulnerability discovery.                tionally, unlike M OVERY, V1 SCAN only targets vulnerabili-
  M OVERY can detect vulnerabilities in which the code lines               ties with code lines deleted from the patch. This is to prevent
deleted from the patch do not exist, but this approach rather              false positives that may occur when considering only the code
generated FPs; a function unrelated to the vulnerability, in               lines added in the patch, but this leads to two FNs. Further-




6550    32nd USENIX Security Symposium                                                                                              USENIX Association
Table 6: Accuracy comparison between the improved version-         Table 7: Accuracy comparison between the improved code-based
based approach of V1 SCAN and C ENTRIS.                            approach of V1 SCAN and VUDDY.
    Target      V1 SCAN (version-based)         C ENTRIS                Target      V1 SCAN (code-based)          VUDDY
   program      #TP    #FP       #FN      #TP      #FP   #FN           program      #TP    #FP     #FN      #TP    #FP  #FN
  Turicreate     23     0         3        22     24     4             Turicreate    13      1       0        9      9       4
   ReactOS       20     0         1         5     47     16             ReactOS      21      1       0       13      8       8
   TizenRT        7     0         0         7     33     0              TizenRT      7       0       0       5       5       2
   Aseprite       3     0         4         7     24     0              Aseprite     8       0       0       3       0       5
  FreeBSD        10     0         2         7     19     5             FreeBSD       12      2       0       10      0       2
  MongoDB         6     0         0         6      9     0             MongoDB       10      0       0        3      3       7
   MAME           1     0         1         2     23     0              MAME          7      2       0        1      0       6
   Filament      3      0         0        3      10     0              Filament     13      0       0        4      3       9
    Godot        4      0         2        2      8      4               Godot        1      0       0        1      0       0
  ArangoDB        1     0         0         1     10     0             ArangoDB       4      0       0        0      2       4
      Total      78     0        13        62     207    29              Total       96      6       0       49      30     47




more, V1 SCAN failed to detect OSS vulnerabilities when the           C ENTRIS discovered only 62 CVE vulnerabilities while
reuse relationship was unclear. For example, vulnerable codes      producing 207 false alarms (i.e., a precision of 23%). When
that were inherited from the Linux Kernel existed in FreeBSD.      C ENTRIS fails to predict the correct component versions, it
V1 SCAN failed to identify the reuse relationship between the      would fail to detect vulnerabilities contained in the reused
Linux Kernel and FreeBSD, resulting in three FNs.                  components (FNs). Additionally, it produced many FPs when
                                                                   (1) the version prediction failed (103 FPs), and (2) a compo-
5.2     Effectiveness of V1 SCAN                                   nent was reused with code modifications (97 FPs). In the latter
                                                                   case, 81 vulnerabilities were not reused in the target program
Next, we evaluate the effectiveness of V1 SCAN compared to         and 16 vulnerabilities were repaired by backporting security
existing version- and code-based approaches. In the experi-        patches. The remaining seven FPs occurred because the CPE
ments, C ENTRIS [36] and VUDDY [14] were leveraged for             provided an incorrect OSS version in that a version without a
the version- and code-based approaches, respectively.              vulnerable function was referred to as vulnerable [8, 35].
Methodology. We first evaluated how the improved version-          Effectiveness of the improved code-based approach. The
and code-based approaches of V1 SCAN enhance vulnerabil-           improved code-based approach used by V1 SCAN detected
ity detection accuracy over the baselines individually (i.e.,      twice as many TPs as VUDDY (see Table 7).
C ENTRIS and VUDDY). Thereafter, we assessed the effec-               It is noteworthy that V1 SCAN covered all vulnerabilities de-
tiveness of V1 SCAN by comparing its vulnerability detection       tected by VUDDY. Specifically, V1 SCAN could detect seven
results with the combined results (union) of C ENTRIS and          CVE vulnerabilities that existed outside of functions by us-
VUDDY. We used the vulnerability dataset (4,612 CVE vul-           ing the vulnerable code classification technique. Moreover,
nerabilities) collected in Section 4.3, and used the same target   V1 SCAN could discover modified vulnerable codes by com-
programs (Table 4) and metrics introduced in Section 5.1. As       posing a signature with core code lines related to vulnerabil-
in the previous experiment, TPs and FPs were established           ities. V1 SCAN produced six FPs owing to the similar code
through manual analysis. Finally, when comparing two ap-           logic in OSS components, as explained in Section 5.1.
proaches here, if a vulnerability detected by one approach            In contrast, VUDDY reported 47 FNs (a 51% TP detec-
goes undetected by the other approach, it is considered a false    tion rate). It failed to detect most vulnerabilities when the
negative of the latter. Therefore, in subsequent experiments,      propagated vulnerable code underwent syntax changes. In
FNs are may differ from that introduced in Section 5.1.            addition, VUDDY could not detect vulnerabilities that exist
Effectiveness of the improved version-based approach.              outside of functions (e.g., macro vulnerabilities) because it
The improved version-based approach of V1 SCAN was sub-            only considered function units.
stantially better accurate than C ENTRIS (see Table 6). It dis-       Furthermore, VUDDY produced 30 FPs, mainly because of
covered 78 vulnerabilities in ten target programs without          the abstraction method (see Section 2.4). When the security
producing any false alarms by using reuse code classification.     patch changes only the abstraction targets (e.g., parameters
V1 SCAN reported 13 FNs that occurred when a vulnerability         and local variable names), VUDDY cannot differentiate be-
contained in the less frequent version of the OSS (not a preva-    tween vulnerable and patched functions, resulting in an FP
lent version) was reused in the target program, or because it      being reported. Finally, if the code of the function to which the
was accidentally filtered out during the filtering process. Note   security patch is applied is extremely short and general (e.g.,
that some of these FNs can be overcome with the improved           a single line return statement), VUDDY mistakenly detects
code-based approach of V1 SCAN.                                    lines of code that are similar but safe as being vulnerable.



USENIX Association                                                                   32nd USENIX Security Symposium              6551
Table 8: Accuracy comparison between V1 SCAN and the com-                               100




                                                                     Elapsed time (s)
bined (union) results of C ENTRIS and VUDDY.                                            80

  Target             V1 SCAN                    Union                                   60
 program      #TP #FP #FN P        R     #TP #FP #FN P         R                        40

 Turicreate   32    1   2    0.97 0.94   30   32     4   0.48 0.88                      20
  ReactOS     26    1   1    0.96 0.96   15   55    12   0.21 0.56                       0
  TizenRT      9    0   0    1.00 1.00    9   38     0   0.19 1.00                            1   10   100     1K      10K     100K      1M   10M   100M
  Aseprite     8    0   4    1.00 0.67   10   24     2   0.29 0.83                                      C/C++ Lines of Code (log scaled)
 FreeBSD      19    2   0    0.90 1.00   13   19     6   0.41 0.68
                                                                     Figure 5: Elapsed time for vulnerability detection in 4,434 popu-
 MongoDB      14    0   0    1.00 1.00    9   11     5   0.45 0.64
  MAME         7    2   1    0.78 0.88   3    23     5   0.12 0.38   lar C/C++ software programs with various code sizes.
  Filament    14    0   0    1.00 1.00   5    13     9   0.28 0.36
   Godot      4     0   2    1.00 0.67   3    8      3   0.27 0.50
 ArangoDB      4    0   0    1.00 1.00    1   12     3   0.08 0.25      Figure 5 illustrates the time measurement result. We ob-
                                                                     served that V1 SCAN detected vulnerabilities in most of the
   Total      137   6   10   0.96 0.93   98   235   49   0.29 0.67
                                                                     target programs (99%) within 20 seconds. The target pro-
                                                                     gram that required the longest time was FreeBSD (86 sec-
Comparison with the combined results. Finally, we com-               onds), which contained many OSS components and had a
pared the vulnerability detection results of V1 SCAN to the          large codebase size. Overall, the time V1 SCAN required for
combined results of C ENTRIS and VUDDY. Table 8 summa-               vulnerability detection was proportional to the codebase size
rizes the experimental results. Despite combining the results        of the target program, but several factors, such as the number
of C ENTRIS and VUDDY, V1 SCAN could detect 40% more                 of components and vulnerabilities contained in the prevalent
vulnerabilities than the combined results while eliminating          versions also affected the elapsed time.
more than 97% of FPs. The code-based approach used by                   Compared to the existing code-based approaches (e.g.,
V1 SCAN could address several FNs of the version-based ap-           [12, 14, 34, 37]), which took an average of 10 s to detect vul-
proach of V1 SCAN; by synergistically consolidating the two          nerabilities in a target program, it is noteworthy that V1 SCAN
results, V1 SCAN discovered more vulnerabilities than either         did not differ significantly in terms of the time required, even
approach in a precise manner.                                        though it used both the improved version- and code-based
   In summary, each of the improved version- and code-based          approaches and showed much higher detection accuracy. In
techniques used in V1 SCAN showed higher accuracy than ex-           summary, the discovery of vulnerabilities within 20 seconds
isting version- and code-based approaches. Even combining            in 99% of the target programs (even with large codebase sizes)
the results of existing approaches, V1 SCAN showed signifi-          suggests that V1 SCAN delivers high performance combined
cantly better detection accuracy. The comprehensive approach         with scalability and is suitable for practical use.
of V1 SCAN, which systematically overcomes the problem of
the many FPs and FNs generated by the respective existing            6                   Discussion
approaches, can be considered highly effective.
                                                                     Practicality of V1 SCAN. We applied V1 SCAN to the latest
                                                                     versions of various software programs to evaluate its practi-
5.3    Performance and scalability
                                                                     cality. To this end, we randomly selected 100 GitHub C/C++
The performance and scalability of V1 SCAN were measured             repositories with over 1,000 stargazers, including the selected
using the dataset built by C ENTRIS [36], which revealed that        target programs in Section 5.1 and other popular software
4,434 popular GitHub C/C++ software programs reused one              programs (e.g., Git and Linux kernel).
or more OSS components. We measured the elapsed time                    Consequently, V1 SCAN detected 73 vulnerabilities, of
required for V1 SCAN to detect vulnerabilities in the 4,434          which 14 were successfully reproduced. The failure to repro-
software programs (ranging from 1K to 20M code lines),               duce the vulnerability was due to a compilation error, a failure
excluding the time required for identifying OSS components           to call the vulnerable function, or a publicly unavailable proof
using C ENTRIS (averaged 2 minutes per target software) and          of concept. We reported all the cases in which vulnerabilities
collecting CVE datasets (total 2 hours). The average codebase        were reproduced to the responsible development teams. It is
size of 4,434 software programs was 300K lines of code.              worth noting that the Common Vulnerability Scoring System
   However, manually matching the GitHub and CPE names               (CVSS) for 12 of the 14 reproducible vulnerabilities is “high.”
of all the OSS components detected in the 4,434 software                We introduce an example of the vulnerability discovered
would be a tedious and error-prone task (see Section 4.3).           in LibGDX. V1 SCAN detected that the latest version of
Therefore, we only considered OSS projects that had already          LibGDX, which is a popular cross-platform game develop-
been verified (mapped) in Section 5.1. Note that such OSS            ment framework, used a vulnerable version of the STB library.
projects could cover more than 80% of the components de-             Because the vulnerabilities contained in STB can potentially
tected in the 4,434 software programs.                               lead to a remote code execution attack, a patch is urgently re-



6552    32nd USENIX Security Symposium                                                                                            USENIX Association
quired. We reported two vulnerabilities to the LibGDX team           vulnerable versions were used in the target application. Zhan
in March 2022. They confirmed our report and immediately             et al. [40] proposed ATVHunter to precisely detect versions of
applied the security patches to their codebase.                      third-party libraries using the control flow graph of the appli-
   V1 SCAN also detected vulnerabilities in other software,          cation. Based on the identified versions, they verified whether
including OpenMVG, FreeBSD, and Disque. We reported                  the target application contained known vulnerabilities.
the vulnerabilities to the respective development teams; the            However, their goal was to precisely identify the compo-
FreeBSD team responded that they would fix the vulnerability         nents, and they did not fully consider OSS modifications for
in the subsequent versions. Patch requests are currently pend-       vulnerability detection. Therefore, they may produce many
ing for the four cases, despite our multiple reports. Nonethe-       false alarms in our problem situations (see Section 5.1).
less, we observed that V1 SCAN could be effectively used for         Vulnerable code detection. Several approaches have at-
vulnerability detection in real-world software programs.             tempted to discover vulnerable code in target programs (e.g.,
Limitations. V1 SCAN makes several assumptions that limit            [3, 12, 14, 34, 37]). Jang et al. [12] proposed ReDeBug, a
its application.                                                     token-level vulnerable code clone detection approach that
   First, V1 SCAN can be applied only when the source code           uses a sliding window technique. Kim et al. [14] presented
of the target program is available.                                  VUDDY, a function-level vulnerable code clone detection ap-
   Second, although V1 SCAN outperformed the existing ap-            proach that can scalably detect 1-day vulnerabilities. Bowman
proaches, it may fail to detect several vulnerabilities. A typical   et al. [3] proposed VGRAPH, a code property graph based
example other than those introduced in Section 5.1 is the vul-       vulnerable code detection approach that is robust to code
nerability in which CPE is incorrectly provided and, at the          modification. Xiao et al. [37] presented MVP, a recurring
same time, reused with significant code changes. To address          vulnerability detection approach, which can discover vulner-
this problem, we can devise a CPE verification technique             able code that recurs with different syntax. Woo et al. [34]
(e.g., [6, 8, 35]) or apply a more relaxed code-based approach.      proposed MOVERY, an approach that can precisely detect
However, the former is beyond the scope of this paper, and par-      modified vulnerable code clones.
ticular caution is needed, as the latter may produce more FPs.          Although their goals are similar to ours, they did not con-
Additionally, while V1 SCAN can handle the syntax diversity          sider vulnerable code whose code has changed significantly
of vulnerable codes, it may not detect propagated vulnerable         owing to the modified OSS reuse, which led to the production
functions that do not contain the code lines deleted in the          of false negatives when applied to our target problem. Also,
patch. This is a result of our decision to avoid potential FPs       they cannot counteract vulnerabilities that exist outside of the
(Section 5.1), but it may result in the reporting of several FNs.    selected granularity (see Section 5.1 and Section 6). Other
   Third, V1 SCAN may not be able to filter code vulnerabil-         approaches have attempted to detect vulnerabilities based on
ities resolved by security patches applied by the developers         learning algorithms (e.g., [18, 19]). These approaches can be
themselves. To solve this problem, we are considering apply-         applied to discover general vulnerable code; however, they
ing semantic analysis to vulnerable and patched codes.               are not applicable for detecting 1-day vulnerabilities.
   Finally, the accuracy of V1 SCAN can be affected by the           Code clone detection. Many approaches attempted to detect
performance of external tools. For example, C ENTRIS can             code clones (e.g., [4, 13, 24–27, 31]). However, as verified in
incorrectly identify components, causing V1 SCAN to produce          the previous studies (e.g., [14, 37]), they generate numerous
FPs. In addition, FPs and FNs may be generated owing to the          false alarms when applied to detect vulnerable code. Hence,
selected function parser and LSH algorithm (see Section 5.1).        they cannot be directly applied to solving our target issue.
If this becomes an issue, V1 SCAN can be plugged into other
tools to enhance the vulnerability discovery accuracy.
                                                                     8   Conclusion
7   Related work
                                                                     Detecting known security vulnerabilities in third-party OSS
Software composition analysis. Several approaches have               components is the first step toward achieving secure software.
attempted to detect third-party OSS components reused in             In this regard, we presented V1 SCAN, which is a precise ap-
target programs (e.g., [2, 9, 17, 20, 28, 36, 40, 41]); some of      proach for detecting 1-day vulnerabilities from modified OSS
these can be used to detect vulnerabilities. Woo et al. [36] pre-    components in a target program. V1 SCAN significantly out-
sented C ENTRIS to identify the modified OSS components in           performed existing approaches in terms of 1-day vulnerability
a target program. It significantly reduces false alarms in com-      discovery accuracy by consolidating version- and code-based
ponent identification by considering only the unique parts of        approaches, along with the reused code classification and
the OSS through code segmentation. Duan et al. [9] proposed          vulnerable code classification techniques. Equipped with the
OSSPolice to identify 1-day vulnerabilities from the third-          vulnerability detection results of V1 SCAN, developers can
party libraries of an Android application. It utilizes constant      mitigate the potential risks imposed by modified third-party
features to extract library versions, and determines whether         OSS reuse, rendering a safer software ecosystem.



USENIX Association                                                                     32nd USENIX Security Symposium          6553
Acknowledgment                                                 [7] Alexandre Decan and Tom Mens. What Do Pack-
                                                                   age Dependencies Tell Us About Semantic Version-
We appreciate the anonymous shepherd and reviewers for             ing? IEEE Transactions on Software Engineering (TSE),
their valuable comments to improve the paper. This work            47(6):1226–1240, 2019.
was supported by Institute of Information & Communications
Technology Planning & Evaluation (IITP) grant funded by        [8] Ying Dong, Wenbo Guo, Yueqi Chen, Xinyu Xing,
the Korea government Ministry of Science and ICT (MSIT)            Yuqing Zhang, and Gang Wang. Towards the detec-
(No.2022-0-00277, Development of SBOM Technologies for             tion of inconsistencies in public security vulnerability
Securing Software Supply Chains, No.2022-0-01198, Con-             reports. In Proceedings of the 28th USENIX Security
vergence Security Core Talent Training Business, and IITP-         Symposium (Security), pages 869–885, 2019.
2023-2020-0-01819, ICT Creative Consilience program).          [9] Ruian Duan, Ashish Bijlani, Meng Xu, Taesoo Kim, and
                                                                   Wenke Lee. Identifying Open-Source License Violation
Availability                                                       and 1-day Security Risk at Large Scale. In Proceed-
                                                                   ings of the 24th ACM SIGSAC Conference on Computer
The source code and datasets of V1 SCAN is publicly avail-         and Communications Security (CCS), pages 2169–2185,
able at GitHub: https://github.com/wooseunghoon/                   2017.
V1SCAN-public.                                                [10] GitHub. The world’s leading software development
                                                                   platform, 2023. https://github.com/.
References                                                    [11] Hyunji Hong, Seunghoon Woo, Eunjin Choi, Jihyun
 [1] Mansour Ahmadi, Reza Mirzazade Farkhani, Ryan                 Choi, and Heejo Lee. xVDB: A High-Coverage Ap-
     Williams, and Long Lu. Finding Bugs Using Your Own            proach for Constructing a Vulnerability Database. IEEE
     Code: Detecting Functionally-similar yet Inconsistent         Access, 10:85050–85063, 2022.
     Code. In 30th USENIX Security Symposium (USENIX          [12] Jiyong Jang, Abeer Agrawal, and David Brumley. Re-
     Security 21), pages 2025–2040, 2021.                          DeBug: Finding Unpatched Code Clones in Entire OS
                                                                   Distributions. In Proceedings of the 33rd IEEE Sympo-
 [2] Michael Backes, Sven Bugiel, and Erik Derr. Reliable
                                                                   sium on Security and Privacy (SP), pages 48–62, 2012.
     Third-Party Library Detection in Android and its Se-
     curity Applications. In Proceedings of the 23rd ACM      [13] Lingxiao Jiang, Ghassan Misherghi, Zhendong Su, and
     SIGSAC Conference on Computer and Communications              Stephane Glondu. DECKARD: Scalable and Accurate
     Security (CCS), pages 356–367, 2016.                          Tree-based Detection of Code Clones. In Proceedings
                                                                   of the 29th International Conference on Software Engi-
 [3] Benjamin Bowman and H Howie Huang. VGRAPH:                    neering (ICSE), pages 96–105, 2007.
     A Robust Vulnerable Code Clone Detection System
     Using Code Property Triplets. In Proceedings of the      [14] Seulbae Kim, Seunghoon Woo, Heejo Lee, and Hakjoo
     5th IEEE European Symposium on Security and Privacy           Oh. VUDDY: A Scalable Approach for Vulnerable
     (EuroS&P), pages 53–69, 2020.                                 Code Clone Discovery. In Proceedings of the 38th
                                                                   IEEE Symposium on Security and Privacy (SP), pages
 [4] Lutz Büch and Artur Andrzejak. Learning-Based Re-             595–614, 2017.
     cursive Aggregation of Abstract Syntax Trees for Code
     Clone Detection. In Proceedings of the IEEE 26th In-     [15] Seongkyeong Kwon, Seunghoon Woo, Gangmo Seong,
     ternational Conference on Software Analysis, Evolution        and Heejo Lee. OCTOPOCS: Automatic Verification
     and Reengineering (SANER), pages 95–104, 2019.                of Propagated Vulnerable Code Using Reformed Proofs
                                                                   of Concept. In 2021 51st Annual IEEE/IFIP Interna-
 [5] Ctags. Universal Ctags, 2023. https://github.com/             tional Conference on Dependable Systems and Networks
     universal-ctags/ctags.                                        (DSN), pages 174–185, 2021.
 [6] Jiarun Dai, Yuan Zhang, Hailong Xu, Haiming Lyu,         [16] Frank Li and Vern Paxson. A Large-Scale Empirical
     Zicheng Wu, Xinyu Xing, and Min Yang. Facilitating            Study of Security Patches. In Proceedings of the 24th
     Vulnerability Assessment through PoC Migration. In            ACM SIGSAC Conference on Computer and Communi-
     Proceedings of the 2021 ACM SIGSAC Conference on              cations Security (CCS), pages 2201–2215, 2017.
     Computer and Communications Security, pages 3300–
                                                              [17] Menghao Li, Wei Wang, Pei Wang, Shuai Wang, Ding-
     3317, 2021.
                                                                   hao Wu, Jian Liu, Rui Xue, and Wei Huo. LibD: Scal-
                                                                   able and Precise Third-party Library Detection in An-
                                                                   droid Markets. In Proceedings of the 39th International



6554   32nd USENIX Security Symposium                                                                USENIX Association
     Conference on Software Engineering (ICSE), pages 335–     [28] Wei Tang, Du Chen, and Ping Luo. BCFinder: A
     346. IEEE, 2017.                                               Lightweight and Platform-independent Tool to Find
                                                                    Third-party Components in Binaries. In Proceedings of
[18] Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Hanchao             the 25th Asia-Pacific Software Engineering Conference
     Qi, and Jie Hu. VulPecker: An Automated Vulnerability          (APSEC), pages 288–297. IEEE, 2018.
     Detection System Based on Code Similarity Analysis.
     In Proceedings of the 32nd Annual Conference on Com-      [29] National Telecommunications and Information Admin-
     puter Security Applications (ACSAC), pages 201–213,            istration. NTIA Software Component Transparency
     2016.                                                          with SBOM (Software Bill of Materials), 2023. https:
                                                                    //www.ntia.doc.gov/SoftwareTransparency.
[19] Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin,
     Sujuan Wang, Zhijun Deng, and Yuyi Zhong. VulDeeP-        [30] TLSH. Trend Micro Locality Sensitive Hash, 2023.
     ecker: A Deep Learning-Based System for Vulnerability          https://github.com/trendmicro/tlsh.
     Detection. In Proceedings of the 25th Annual Network      [31] Pengcheng Wang, Jeffrey Svajlenko, Yanzhao Wu, Yun
     and Distributed System Security Symposium (NDSS),              Xu, and Chanchal K Roy. CCAligner: A Token Based
     2018.                                                          Large-Gap Clone Detector. In Proceedings of the
[20] Ziang Ma, Haoyu Wang, Yao Guo, and Xiangqun Chen.              40th International Conference on Software Engineering
     LibRadar: Fast and Accurate Detection of Third-party           (ICSE), pages 1066–1077, 2018.
     Libraries in Android Apps. In Proceedings of the          [32] Wikipedia. Jaccard similarity, 2023. https://en.
     38th International Conference on Software Engineer-            wikipedia.org/wiki/Jaccard_index.
     ing: Companion (ICSE-Companion), pages 653–656,
     2016.                                                     [33] Wikipedia.    Locality-sensitive hashing, 2023.
                                                                    https://en.wikipedia.org/wiki/Locality-
[21] NVD. Common Platform and Enumeration (CPE), 2023.              sensitive_hashing.
     https://nvd.nist.gov/products/cpe.
                                                               [34] Seunghoon Woo, Hyunji Hong, Eunjin Choi, and Heejo
[22] NVD. National Vulnerability Database, 2023. https:             Lee. MOVERY: A Precise Approach for Modified Vul-
     //nvd.nist.gov/.                                               nerable Code Clone Discovery from Modified Open-
                                                                    Source Software Components. In Proceedings of the
[23] Jonathan Oliver, Chun Cheng, and Yanggui Chen.                 31st USENIX Security Symposium (Security), pages
     TLSH–a locality sensitive hash. In Proceedings of the          3037–3053, 2022.
     2013 Fourth Cybercrime and Trustworthy Computing
     Workshop, pages 7–13, 2013.                               [35] Seunghoon Woo, Dongwook Lee, Sunghan Park, Heejo
                                                                    Lee, and Sven Dietrich. V0Finder: Discovering the
[24] Chaiyong Ragkhitwetsagul and Jens Krinke. Siamese:             Correct Origin of Publicly Reported Software Vulner-
     Scalable and Incremental Code Clone Search via Mul-            abilities. In Proceedings of the 30th USENIX Security
     tiple Code Representations. Empirical Software Engi-           Symposium (Security), pages 3041–3058, 2021.
     neering, pages 2236–2284, 2019.
                                                               [36] Seunghoon Woo, Sunghan Park, Seulbae Kim, Heejo
[25] Chanchal K Roy and James R Cordy. NICAD: Accu-                 Lee, and Hakjoo Oh. CENTRIS: A Precise and Scalable
     rate Detection of Near-Miss Intentional Clones Using           Approach for Identifying Modified Open-Source Soft-
     Flexible Pretty-Printing and Code Normalization. In            ware Reuse. In Proceedings of the IEEE/ACM 43rd In-
     Proceedings of the 16th IEEE International Conference          ternational Conference on Software Engineering (ICSE),
     on Program Comprehension (ICPC), pages 172–181,                pages 860–872, 2021.
     2008.
                                                               [37] Yang Xiao, Bihuan Chen, Chendong Yu, Zhengzi Xu,
[26] Hitesh Sajnani, Vaibhav Saini, Jeffrey Svajlenko, Chan-        Zimu Yuan, Feng Li, Binghong Liu, Yang Liu, Wei Huo,
     chal K Roy, and Cristina V Lopes. SourcererCC: Scaling         Wei Zou, and Wenchang Shi. MVP: Detecting Vulnera-
     Code Clone Detection to Big-Code. In Proceedings of            bilities using Patch-Enhanced Vulnerability Signatures.
     the 38th International Conference on Software Engi-            In Proceedings of the 29th USENIX Security Symposium
     neering (ICSE), pages 1157–1168, 2016.                         (Security), pages 1165–1182, 2020.
[27] Yuichi Semura, Norihiro Yoshida, Eunjong Choi, and        [38] Yifei Xu, Zhengzi Xu, Bihuan Chen, Fu Song, Yang
     Katsuro Inoue. CCFinderSW: Clone Detection Tool                Liu, and Ting Liu. Patch Based Vulnerability Matching
     with Flexible Multilingual Tokenization. In Proceedings        for Binary Programs. In Proceedings of the 29th ACM
     of the 24th Asia-Pacific Software Engineering Confer-          SIGSOFT International Symposium on Software Testing
     ence (APSEC), pages 654–659, 2017.                             and Analysis (ISSTA), pages 376–387, 2020.



USENIX Association                                                              32nd USENIX Security Symposium       6555
[39] Fabian Yamaguchi, Nico Golde, Daniel Arp, and Konrad
     Rieck. Modeling and Discovering Vulnerabilities with
     Code Property Graphs. In Proceedings of the 35th IEEE
     Symposium on Security and Privacy (SP), pages 590–
     604. IEEE, 2014.

[40] Xian Zhan, Lingling Fan, Sen Chen, Feng Wu, Tian-
     ming Liu, Xiapu Luo, and Yang Liu. ATVHunter: Re-
     liable Version Detection of Third-Party Libraries for
     Vulnerability Identification in Android Applications. In
     Proceedings of the 43rd International Conference on
     Software Engineering (ICSE), pages 1695–1707. IEEE,
     2021.
[41] Xian Zhan, Tianming Liu, Lingling Fan, Li Li, Sen Chen,
     Xiapu Luo, and Yang Liu. Research on Third-Party Li-
     braries in Android Apps: A Taxonomy and Systematic
     Literature Review. IEEE Transactions on Software En-
     gineering, 2021.




6556   32nd USENIX Security Symposium                           USENIX Association
